# -*- coding: utf-8 -*-
"""skin_analysis.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YLiqG7bsyeEEdcoqVSiXSCmsq12OOtKo
"""

# === All helper functions and full analysis code from Word file goes below ===

# [PASTE COMPLETE CODE FROM WORD FILE HERE - all functions, patch logic, scores, etc.]

# Install and import dependencies


# --- Imports ---
import cv2
import numpy as np
import mediapipe as mp
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
import torch
from torchvision.utils import save_image
from Models.modelv2 import MobileHairNetV2
import math
import os
from PIL import Image
from sklearn.cluster import KMeans
from scipy.stats import gaussian_kde
from skimage.filters import frangi
from skimage import img_as_float
from skimage.morphology import skeletonize
from skimage.color import rgb2gray
from skimage.filters.rank import median
from skimage.morphology import disk
from skimage.feature import graycomatrix, graycoprops
from skimage.filters import median
from skimage import measure



image_path = r"C:\Users\Yash\Desktop\face_app_final\myface.jpg"  # Path to your image

####################################FOREHEAD PATCH#######################################
# !git clone https://github.com/wonbeomjang/mobile-hair-segmentation-pytorch.git
# %cd mobile-hair-segmentation-pytorch


# --- Hair segmentation on cropped image ---
def get_hair_mask(image_path, output_path="hair_mask.png"):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    net = MobileHairNetV2(pretrained=True).to(device)
    image = Image.open(image_path).convert("RGB")
    orig_size = image.size
    image_tensor = TF.to_tensor(image).to(device)
    image_tensor = TF.resize(image_tensor, [224, 224])
    image_tensor = TF.normalize(image_tensor, [0.5]*3, [0.5]*3)
    with torch.no_grad():
        mask = net(image_tensor.unsqueeze(0)).argmax(dim=1)
        mask = TF.resize(mask, list(orig_size[::-1])).squeeze()
    save_image(mask.float(), output_path)
    return output_path


    
    # --- Load full image ---
img_path = r"C:\Users\Yash\Desktop\face_app_final\myface.jpg"  # test image path
img_cv = cv2.imread(img_path)

if img_cv is None:
    raise ValueError("Image not found!")

img_rgb = cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB)
H, W = img_rgb.shape[:2]
img_pil = Image.fromarray(img_rgb)

# --- Get nose Y using MediaPipe ---
mp_face_mesh = mp.solutions.face_mesh
with mp_face_mesh.FaceMesh(static_image_mode=True) as face_mesh:
    results = face_mesh.process(img_rgb)
    if not results.multi_face_landmarks:
        raise ValueError("❌ No face detected.")
    landmarks = results.multi_face_landmarks[0].landmark
    nose_y = int(landmarks[1].y * H)

# --- Crop image above nose ---
img_above_np = img_rgb[:nose_y, :, :]
img_above = Image.fromarray(img_above_np)
img_above.save("img_above.png")

# --- Segment hair on upper part only ---
mask_path = get_hair_mask("img_above.png", "hair_mask_above.png")
hair_mask = Image.open(mask_path).convert("L")
hair_mask = hair_mask.point(lambda x: 1 if x > 128 else 0)
hair_mask_np = np.array(hair_mask)

print(" Test run completed.")


# --- Define patch using averaged landmarks ---
def extract_forehead_patch_above_nose(
    full_img, cropped_above_img, hair_mask_np, landmark_list,
    idx_left_pair, idx_right_pair, buffer_px=5,
    min_ratio=0.4, max_attempts=5, shrink_factor=0.2
):
    img_width = cropped_above_img.width
    img_height = cropped_above_img.height

    def avg_xy(idx_pair):
        x = (landmark_list[idx_pair[0]].x + landmark_list[idx_pair[1]].x) / 2
        y = (landmark_list[idx_pair[0]].y + landmark_list[idx_pair[1]].y) / 2
        return int(x * img_width), int(y * H)

    x1, y1 = avg_xy(idx_left_pair)
    x2, y2 = avg_xy(idx_right_pair)

    x_left_orig = min(x1, x2)
    x_right_orig = max(x1, x2)
    y_bottom = min(y1, y2, nose_y)
    y_bottom = min(y_bottom, img_height)

    # --- Step 1: Initial patch_top ---
    def compute_patch_top(xl, xr):
        patch_top = 0
        for x in range(xl, xr):
            column = hair_mask_np[:, x]
            hair_pixels = np.where((column == 1) & (np.arange(len(column)) < y_bottom))[0]
            if len(hair_pixels) > 0:
                lowest_y = hair_pixels[-1]
                patch_top = max(patch_top, lowest_y + buffer_px)
        return min(patch_top, y_bottom - 1)

    patch_top = compute_patch_top(x_left_orig, x_right_orig)

    x_left = x_left_orig
    x_right = x_right_orig

    # --- Step 2: Adjust width if aspect ratio too low ---
    attempt = 0
    while attempt < max_attempts:
        patch_height = y_bottom - patch_top
        patch_width = x_right - x_left
        aspect_ratio = patch_height / patch_width

        if aspect_ratio >= min_ratio:
            break

        # Shrink width
        shrink_by = int(shrink_factor * patch_width)
        if shrink_by < 2:
            break

        center = (x_left + x_right) // 2
        new_half = (patch_width - shrink_by) // 2
        x_left = max(center - new_half, 0)
        x_right = min(center + new_half, img_width)

        patch_top = compute_patch_top(x_left, x_right)
        attempt += 1
        print(f" Reduced width attempt {attempt} | New aspect ratio: {aspect_ratio:.2f}")

        # --- Step 3: Extend width left and right within landmark bounds (only if hair is not inside box) ---
    while x_left > x_left_orig:
        x_new = x_left - 1
        sub_mask = hair_mask_np[patch_top:y_bottom, x_new:x_right]
        if np.any(sub_mask == 1):
            break
        x_left = x_new

    while x_right < x_right_orig:
        x_new = x_right + 1
        sub_mask = hair_mask_np[patch_top:y_bottom, x_left:x_new]
        if np.any(sub_mask == 1):
            break
        x_right = x_new

    # --- Step 4: Extend patch_top upward (only if no hair comes inside box) ---
    while patch_top > 0:
        y_new = patch_top - 1
        sub_mask = hair_mask_np[y_new:y_bottom, x_left:x_right]
        if np.any(sub_mask == 1):
            break
        patch_top = y_new

    # Final crop
    patch = cropped_above_img.crop((x_left, patch_top, x_right, y_bottom))
    return patch, (x_left, patch_top, x_right, y_bottom)


# --- Landmark pairs for patch corners ---
idx_left_pair = (104, 105)
idx_right_pair = (333, 334)

# --- Extract forehead patch ---
forehead_patch, coords = extract_forehead_patch_above_nose(
    full_img="myface.jpg",
    cropped_above_img=img_above,
    hair_mask_np=hair_mask_np,
    landmark_list=landmarks,
    idx_left_pair=idx_left_pair,
    idx_right_pair=idx_right_pair,
    buffer_px=5,
    min_ratio=0.3
)

#####################################ALL PATCHES##################################
# Initialize MediaPipe FaceMesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

# shrink_ratio
shrink_ratio_below_eyes = 0.75
shrink_ratio_side_eyes = 0.75
shrink_ratio_nose = 0.80
shrink_ratio_cheeks = 0.75
shrink_ratio_chin = 0.80

# To Balance image
left_most_landmark  = 130
right_most_landmark = 359

TARGET_SIZE = 224

# Indices for each
right_below_eye_indices = [126, 101, 116, 143, 25, 472, 112]
left_below_eye_indices  = [355, 330, 345, 372, 255, 477, 341]

right_cheek_indices = [120,142,206,207,123,116,117,118,119,111]
left_cheek_indices  = [349,371,426,427,352,345,346,347,348,340]

RIGHT_EYE_SIDE_INDICES = [27,46,156,118,24]
LEFT_EYE_SIDE_INDICES  = [257,276,383,347,254]
RIGHT_EYE_MASK_INDICES = [226, 113, 30, 27, 56, 190, 112, 23, 25]
LEFT_EYE_MASK_INDICES  = [446, 342, 260, 257, 286, 414, 341, 253, 255]

nose_indices = [115, 4, 344, 420, 399, 351, 122, 174, 198]
chin_indices = [83,313,418,262,199,32,194]



# get_angle_function
def get_rotation_angle(p1, p2):
    dx = p2[0] - p1[0]
    dy = p2[1] - p1[1]
    angle = math.degrees(math.atan2(dy, dx))
    return angle

# return rotated image
def rotate_image(image, angle):
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)

    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))

    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    rotated = cv2.warpAffine(image, M, (new_w, new_h), borderValue=(255, 255, 255))
    return rotated

# extract patches for all except side_eye
def extract_patch(image, landmark_points, shrink_ratio=0.8):
    h, w = image.shape[:2]
    points = np.array([[int(pt.x * w), int(pt.y * h)] for pt in landmark_points], np.int32)

    x_min, y_min = points.min(axis=0)
    x_max, y_max = points.max(axis=0)

    box_w = x_max - x_min
    box_h = y_max - y_min

    shrink_w = int(box_w * shrink_ratio)
    shrink_h = int(box_h * shrink_ratio)

    center_x = (x_min + x_max) // 2
    center_y = (y_min + y_max) // 2

    x1 = max(0, center_x - shrink_w // 2)
    y1 = max(0, center_y - shrink_h // 2)
    x2 = min(w, center_x + shrink_w // 2)
    y2 = min(h, center_y + shrink_h // 2)

    return image[y1:y2, x1:x2]

# extract patch for only side-eye
def extract_patch_side_eye(image, landmark_points, eye_mask_points=None, shrink_ratio=0.8):
    h, w = image.shape[:2]
    points = np.array([[int(pt.x * w), int(pt.y * h)] for pt in landmark_points], np.int32)

    x_min, y_min = points.min(axis=0)
    x_max, y_max = points.max(axis=0)
    box_w = x_max - x_min
    box_h = y_max - y_min

    shrink_w = int(box_w * shrink_ratio)
    shrink_h = int(box_h * shrink_ratio)
    center_x = (x_min + x_max) // 2
    center_y = (y_min + y_max) // 2

    x_start = max(0, center_x - shrink_w // 2)
    y_start = max(0, center_y - shrink_h // 2)
    x_end = min(w, center_x + shrink_w // 2)
    y_end = min(h, center_y + shrink_h // 2)

    patch = image[y_start:y_end, x_start:x_end].copy()

    if patch.size == 0 or patch.ndim != 3 or patch.shape[2] != 3:
        print("⚠ Skipping invalid patch:", patch.shape)
        return np.zeros((TARGET_SIZE, TARGET_SIZE, 3), dtype=np.uint8)

    if eye_mask_points:
        mask = np.zeros(patch.shape[:2], dtype=np.uint8)
        eye_poly = np.array([[int(pt.x * w) - x_start, int(pt.y * h) - y_start] for pt in eye_mask_points], np.int32)
        cv2.fillPoly(mask, [eye_poly], 255)
        patch = cv2.inpaint(patch, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

        # Begin corrected white-pixel filling logic
        white_mask = np.all(patch == 255, axis=2)
        patch_float = patch.astype(np.float32)
        h_patch, w_patch = patch.shape[:2]

        x_color_avg = {}
        y_color_avg = {}

        # X-based skin sampling (same column, up to 3 above and 3 below each white pixel)
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    color_sum = np.zeros(3)
                    count = 0
                    for offset in range(1, 4):
                        above_y = y - offset
                        below_y = y + offset
                        if 0 <= above_y < h_patch and not white_mask[above_y, x]:
                            color_sum += patch_float[above_y, x]
                            count += 1
                        if 0 <= below_y < h_patch and not white_mask[below_y, x]:
                            color_sum += patch_float[below_y, x]
                            count += 1
                    if count > 0:
                        x_color_avg[(y, x)] = color_sum / count

        # Y-based skin sampling (same row, up to 3 left and right of each white pixel)
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    color_sum = np.zeros(3)
                    count = 0
                    for offset in range(1, 4):
                        left_x = x - offset
                        right_x = x + offset
                        if 0 <= left_x < w_patch and not white_mask[y, left_x]:
                            color_sum += patch_float[y, left_x]
                            count += 1
                        if 0 <= right_x < w_patch and not white_mask[y, right_x]:
                            color_sum += patch_float[y, right_x]
                            count += 1
                    if count > 0:
                        y_color_avg[(y, x)] = color_sum / count

        # Apply average of both x and y-based values
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    col_x = x_color_avg.get((y, x))
                    col_y = y_color_avg.get((y, x))
                    if col_x is not None and col_y is not None:
                        patch[y, x] = ((col_x + col_y) / 2).astype(np.uint8)
                    elif col_x is not None:
                        patch[y, x] = col_x.astype(np.uint8)
                    elif col_y is not None:
                        patch[y, x] = col_y.astype(np.uint8)
        # End white fill

    # Resize patch while keeping aspect ratio, no padding
    ph, pw = patch.shape[:2]
    if ph >= pw:
        new_h = TARGET_SIZE
        new_w = int(pw * (TARGET_SIZE / ph))
    else:
        new_w = TARGET_SIZE
        new_h = int(ph * (TARGET_SIZE / pw))

    patch = cv2.resize(patch, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return patch



# Main Process
def process_image(image):
    if image is None:
        raise ValueError("Image is empty or could not be loaded.")
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(image_rgb)

    if not results.multi_face_landmarks:
        print(" Face not detected in input image")
        return {}

    landmarks = results.multi_face_landmarks[0].landmark
    h, w, _ = image.shape

    pt1 = (int(landmarks[left_most_landmark].x * w), int(landmarks[left_most_landmark].y * h))
    pt2 = (int(landmarks[right_most_landmark].x * w), int(landmarks[right_most_landmark].y * h))

    # Rotate image
    angle = get_rotation_angle(pt1, pt2)
    rotated_image = rotate_image(image, angle)

    # Detect landmarks on rotated image
    rotated_rgb = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)
    rotated_results = face_mesh.process(rotated_rgb)
    if not rotated_results.multi_face_landmarks:
        print(" Face not detected after rotation")
        return {}

    rotated_landmarks = rotated_results.multi_face_landmarks[0].landmark

    # Extract cheek patches
    right_cheek = extract_patch(rotated_image, [rotated_landmarks[i] for i in right_cheek_indices], shrink_ratio_cheeks)
    left_cheek  = extract_patch(rotated_image, [rotated_landmarks[i] for i in left_cheek_indices], shrink_ratio_cheeks)

    right_below_eye = extract_patch(rotated_image, [rotated_landmarks[i] for i in right_below_eye_indices], shrink_ratio_below_eyes)
    left_below_eye  = extract_patch(rotated_image, [rotated_landmarks[i] for i in left_below_eye_indices], shrink_ratio_below_eyes)

    nose = extract_patch(rotated_image, [rotated_landmarks[i] for i in nose_indices], shrink_ratio_nose)
    chin = extract_patch(rotated_image, [rotated_landmarks[i] for i in chin_indices], shrink_ratio_chin)

    right_side_eye = extract_patch_side_eye(rotated_image, [landmarks[i] for i in RIGHT_EYE_SIDE_INDICES],
                    eye_mask_points=[landmarks[i] for i in RIGHT_EYE_MASK_INDICES], shrink_ratio=shrink_ratio_side_eyes)

    left_side_eye  = extract_patch_side_eye(rotated_image, [landmarks[i] for i in LEFT_EYE_SIDE_INDICES],
                    eye_mask_points=[landmarks[i] for i in LEFT_EYE_MASK_INDICES], shrink_ratio=shrink_ratio_side_eyes)



    # Convert to RGB
    right_cheek_rgb = cv2.cvtColor(right_cheek, cv2.COLOR_BGR2RGB)
    left_cheek_rgb = cv2.cvtColor(left_cheek, cv2.COLOR_BGR2RGB)
    right_below_eye_rgb = cv2.cvtColor(right_below_eye, cv2.COLOR_BGR2RGB)
    left_below_eye_rgb = cv2.cvtColor(left_below_eye, cv2.COLOR_BGR2RGB)
    nose_rgb = cv2.cvtColor(nose, cv2.COLOR_BGR2RGB)
    chin_rgb = cv2.cvtColor(chin, cv2.COLOR_BGR2RGB)
    right_side_eye_rgb = cv2.cvtColor(right_side_eye, cv2.COLOR_BGR2RGB)
    left_side_eye_rgb = cv2.cvtColor(left_side_eye, cv2.COLOR_BGR2RGB)

    forehead_rgb = np.array(forehead_patch)  # Convert PIL to NumPy RGB

    return {
        'right_cheek': right_cheek_rgb,
        'left_cheek': left_cheek_rgb,
        'right_below_eye': right_below_eye_rgb,
        'left_below_eye': left_below_eye_rgb,
        'nose': nose_rgb,
        'chin': chin_rgb,
        'right_side_eye': right_side_eye_rgb,
        'left_side_eye': left_side_eye_rgb,
        'forehead': forehead_rgb
    }


image_bgr = cv2.imread(image_path)
patches = process_image(image_bgr)

# print(patches['right_below_eye'].shape)
plt.imshow(patches['forehead'])
plt.axis('off')


##################HIDDEN DARKSPOTS############################
# ====== SHARPENING KERNELS ======
basic_kernel = np.array([[0, -1, 0],
                         [-1, 5, -1],
                         [0, -1, 0]], dtype=np.float32)

strong_kernel = np.array([[0, -1, 0],
                          [-1, 5, -1],
                          [0, -1, 0]], dtype=np.float32)

# ====== SUPPORT FUNCTIONS ======
def compute_alpha(l_channel):
    mean_l = np.mean(l_channel)
    std_l = np.std(l_channel)
    alpha_brightness = 1 - (mean_l / 255)
    alpha_contrast = 1 - (std_l / 64)
    alpha = np.clip(0.5 * alpha_brightness + 0.5 * alpha_contrast, 0, 1)
    return alpha

def get_adaptive_kernel(alpha):
    return (1 - alpha) * basic_kernel + alpha * strong_kernel

def process_with_kernel(l_channel, kernel):
    sharpened = cv2.filter2D(l_channel, -1, kernel)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    return clahe.apply(sharpened)

# ====== MAIN PROCESSING FUNCTION ======
def enhance_dry_patch_single(image_path):
    """
    Enhances dryness-relevant features in a single image and returns the result as an RGB numpy array.
    """
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f" Could not read image: {image_path}")

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)

    alpha = compute_alpha(l)
    adaptive_kernel = get_adaptive_kernel(alpha)

    l_adaptive = process_with_kernel(l, adaptive_kernel)

    lab_mod = cv2.merge([l_adaptive, a, b])
    final_bgr = cv2.cvtColor(lab_mod, cv2.COLOR_LAB2BGR)
    final_rgb = cv2.cvtColor(final_bgr, cv2.COLOR_BGR2RGB)
    return final_rgb

# # Path to single image
# image_path = "/content/myface3.jpg"

# Get enhanced image (RGB)
enhanced_rgb = enhance_dry_patch_single(image_path)




################Dark Circle###################
# --- Score Mapping ---
def convert_to_score_10(score):
    if score >= 85: return 10
    elif score >= 75: return 9
    elif score >= 65: return 8
    elif score >= 60: return 7
    elif score >= 55: return 6
    elif score >= 50: return 5
    elif score >= 45: return 4
    elif score >= 35: return 3
    elif score >= 25: return 2
    else: return 1

# --- KDE Threshold Helper ---
def adaptive_kde_threshold(channel_data, fraction=0.10):
    flat = channel_data.flatten()
    flat = flat[flat > 0]
    kde = gaussian_kde(flat)
    x = np.linspace(np.min(flat), np.max(flat), 256)
    y = kde(x)
    cdf = np.cumsum(y)
    cdf /= cdf[-1]
    idx = np.where(cdf >= fraction)[0][0]
    return x[idx]

# --- Main Function ---
def compute_image_score(img_rgb):
    img_np = np.array(img_rgb)
    H, W = img_np.shape[:2]
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

    exclusion_mask = np.ones((H, W), dtype=np.uint8)
    buffer_w = W // 6
    buffer_h = H // 3
    exclusion_mask[H-buffer_h:, :buffer_w] = 0
    exclusion_mask[H-buffer_h:, W-buffer_w:] = 0

    # LAB Redness
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l_channel, a_channel, b_channel = cv2.split(lab)
    a_prime = a_channel.astype(np.int16) - 128
    a_norm = a_prime / (l_channel.astype(np.float32) + 1e-5)
    a_thresh = np.percentile(a_norm[(a_norm > 0) & (exclusion_mask > 0)], 70)
    red_mask = (a_norm > a_thresh) & (exclusion_mask > 0)
    red_severity = (np.mean(a_norm[red_mask]) - np.mean(a_norm[(~red_mask) & (exclusion_mask > 0)])) / (np.mean(a_norm[(~red_mask) & (exclusion_mask > 0)]) + 1e-5)

    # LAB Blueness
    b_thresh = adaptive_kde_threshold(b_channel[exclusion_mask > 0], 0.10)
    blue_mask = (b_channel <= int(b_thresh)) & (exclusion_mask > 0)
    blue_severity = (-1*np.mean(b_channel[blue_mask]) + np.mean(b_channel[(~blue_mask) & (exclusion_mask > 0)])) / (np.mean(b_channel[blue_mask]) + 1e-5)

    # Darkness (HSV V-channel)
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    v_img = hsv[:, :, 2]
    v_masked = v_img[exclusion_mask > 0]
    kde = gaussian_kde(v_masked.flatten())
    v_vals = np.linspace(0, 255, 256)
    kde_vals = kde(v_vals)
    diffs = np.diff(kde_vals)
    valleys = np.where((np.hstack(([False], diffs[:-1] < 0)) & (np.hstack((diffs[1:] > 0, [False]))))[0])
    if len(valleys) >= 2:
        v_thresh1 = int(v_vals[valleys[0]])
        v_thresh2 = int(v_vals[valleys[1]])
    else:
        km = KMeans(n_clusters=3, random_state=0).fit(v_masked.reshape(-1, 1))
        centers = sorted(km.cluster_centers_.flatten())
        v_thresh1, v_thresh2 = int(centers[0]), int(centers[1])

    thresholds = {
        'low': {'min': v_thresh2 + 1, 'max': 255},
        'moderate': {'min': v_thresh1 + 1, 'max': v_thresh2},
        'high': {'min': 0, 'max': v_thresh1}
    }
    level_masks = {level: cv2.inRange(v_img, cfg['min'], cfg['max']) & exclusion_mask for level, cfg in thresholds.items()}

    v_low = np.median(v_img[level_masks['low'] > 0]) + 1e-5
    v_mid = np.median(v_img[level_masks['moderate'] > 0])
    v_high = np.median(v_img[level_masks['high'] > 0])
    darkness_severity = (v_low / v_high + v_mid / v_high + v_low / v_mid)

    high_area = np.sum(level_masks['high'] > 0)
    moderate_area = np.sum(level_masks['moderate'] > 0)
    low_area = np.sum(level_masks['low'] > 0)

    # Vesselness
    gray = rgb2gray(img_np)
    vesselness = frangi(img_as_float(gray))
    dark_mask_combined = ((level_masks['moderate'] > 0) | (level_masks['high'] > 0))
    vessel_masked = vesselness * dark_mask_combined
    threshold = np.percentile(vessel_masked[vessel_masked > 0], 90) if np.any(vessel_masked > 0) else 1
    vessel_mask = vessel_masked > threshold
    skeleton = skeletonize(vessel_mask)
    skeleton_length = np.sum(skeleton)
    vessel_score = skeleton_length * (vessel_masked[vessel_mask].mean() if np.any(vessel_mask) else 0)/(2*(H + W))

    # Final Score
    final_score = 40*(
        0.8 * ((darkness_severity / 6)**(0.55)) +
        0.05 * (red_severity / 3) +
        0.05 * (blue_severity / 2) +
        0.1 * (vessel_score / 0.6)
    ) * (((high_area + moderate_area)/(high_area + moderate_area + low_area)))*(darkness_severity)*(10/9)

    score_10 = convert_to_score_10(final_score)

    return score_10


# Provide path to your local image (e.g., in Colab or locally)

# Extract left and right below-eye patches
selected_regions = ['left_below_eye', 'right_below_eye']
darkcircle_scores = {}

for region in selected_regions:
    if region in patches:
        score = compute_image_score(patches[region])
        darkcircle_scores[region] = score
    else:
        print(f"Warning: {region} patch not found in patches dictionary.")


##########################DARK SPOTS##############################
import cv2
import numpy as np

def compute_darkspot_score(img):
    intervals = {
        'bound': {'min': 100, 'max': 255},
        'low': {'min': 150, 'max': 255},
        'mid': {'min': 180, 'max': 255},
        'high': {'min': 200, 'max': 255},
    }

    severity_colors = [(0, 0, 255), (128, 0, 128), (255, 0, 0), (0, 255, 0), (0, 0, 0)]  # Red → Black

    def find_clean_contours(mask, shape):
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return [cnt for cnt in contours if not is_touching_border(cnt, shape)]

    def is_touching_border(contour, shape):
        h, w = shape[:2]
        for pt in contour:
            x, y = pt.ravel()
            if x <= 1 or y <= 1 or x >= w - 2 or y >= h - 2:
                return True
        return False

    def is_inside(inner, outer):
        inner_pts = inner.reshape(-1, 2)
        total = len(inner_pts)
        outside = sum(cv2.pointPolygonTest(outer, (float(x), float(y)), False) <= 0 for x, y in inner_pts)
        return (outside / total) <= 0.3

    def merge_contours(inner, outer):
        merged_inner = []
        used = set()
        for oc in outer:
            grouped = []
            for j, ic in enumerate(inner):
                if j not in used and is_inside(ic, oc):
                    grouped.append(ic)
                    used.add(j)
            if len(grouped) > 1:
                merged_inner.append(oc)
        for j in sorted(used, reverse=True):
            del inner[j]
        inner.extend(merged_inner)

    def filter_by_area(contours, bins):
        areas = [cv2.contourArea(c) for c in contours]
        if len(areas) < 2:
            return contours
        thresholds = np.histogram_bin_edges(areas, bins=bins)
        return [c for c in contours if cv2.contourArea(c) > thresholds[1]]

    def map_score_to_10(score):
        if score >= 0.27: return 10
        elif score >= 0.24: return 9
        elif score >= 0.21: return 8
        elif score >= 0.18: return 7
        elif score >= 0.15: return 6
        elif score >= 0.12: return 5
        elif score >= 0.10: return 4
        elif score >= 0.08: return 3
        elif score >= 0.06: return 2
        else: return 1

    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    v_channel = hsv[:, :, 2]

    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a_lab, b_lab = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_clahe = clahe.apply(l)
    lab_clahe = cv2.merge((l_clahe, a_lab, b_lab))
    img_enhanced = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)

    gray = cv2.cvtColor(img_enhanced, cv2.COLOR_BGR2GRAY)
    inverted = 255 - gray
    inv_clahe = clahe.apply(inverted)

    contours_by_label = {
        label: find_clean_contours(cv2.inRange(inv_clahe, cfg['min'], cfg['max']), img.shape)
        for label, cfg in intervals.items()
    }

    red, blue, green, bound = contours_by_label['high'], contours_by_label['mid'], contours_by_label['low'], contours_by_label['bound']
    merge_contours(red, blue)
    merge_contours(blue, green)
    merge_contours(red, green)

    all_contours = (
        filter_by_area(red, 50) +
        filter_by_area(blue, 50) +
        filter_by_area(green, 50) +
        filter_by_area(bound, 20)
    )

    mask_all = np.zeros_like(v_channel, dtype=np.uint8)
    for c in all_contours:
        cv2.drawContours(mask_all, [c], -1, 255, -1)
    healthy_skin_V = np.median(v_channel[mask_all == 0])

    filtered_final = []
    for i, c1 in enumerate(all_contours):
        nested = False
        for j, c2 in enumerate(all_contours):
            if i != j and is_inside(c1, c2):
                if cv2.contourArea(c1) / cv2.contourArea(c2) > 0.25:
                    nested = True
                    break
        if not nested:
            filtered_final.append(c1)

    final_cleaned = []
    for i, c_outer in enumerate(filtered_final):
        area_outer = cv2.contourArea(c_outer)
        inner_sum = sum(cv2.contourArea(c_inner) for j, c_inner in enumerate(filtered_final)
                        if i != j and is_inside(c_inner, c_outer))
        if inner_sum / (area_outer + 1e-5) < 0.6:
            final_cleaned.append(c_outer)

    image_hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(image_hsv)
    image_lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(image_lab)

    results = []
    for i, c in enumerate(final_cleaned):
        mask = np.zeros_like(v, dtype=np.uint8)
        cv2.drawContours(mask, [c], -1, 255, -1)
        acne_mask = (((h < 11.5) | (h > 0)) & (s > 70) & (s < 145) & (a > 142) & (a < 200) & (mask == 255)).astype(np.uint8)
        dark_mask = ((h > 8) & (h < 15) & (s > 50) & (s < 155) & (a > 100) & (a < 155) & (mask == 255)).astype(np.uint8)
        acne_score = np.sum(acne_mask)
        dark_score = np.sum(dark_mask)
        total = acne_score + dark_score + 1e-5
        label = "acne" if acne_score > dark_score else "dark spot"
        confidence = max(acne_score, dark_score) / total
        results.append((i + 1, label, confidence))

    acne_area = sum(cv2.contourArea(final_cleaned[i - 1]) for i, l, _ in results if l == "acne")
    dark_area = sum(cv2.contourArea(final_cleaned[i - 1]) for i, l, _ in results if l == "dark spot")
    pad_indices = set()
    if acne_area / (dark_area + 1e-5) > 0.4:
        for i, (idx, label, conf) in enumerate(results):
            if label == "dark spot":
                results[i] = (idx, "PAD", conf)
                pad_indices.add(idx)

    v_ratios = []
    for idx, label, conf in results:
        if label in ["PAD", "dark spot"]:
            c = final_cleaned[idx - 1]
            mask = np.zeros_like(v, dtype=np.uint8)
            cv2.drawContours(mask, [c], -1, 255, -1)
            lesion_v = v[mask == 255]
            lesion_median = np.median(lesion_v)
            ratio = lesion_median / (healthy_skin_V + 1e-5)
            v_ratios.append((c, ratio))

    if not v_ratios:
        return 0.0, img_bgr  # No lesions, return clean image

    ratios_only = [r for _, r in v_ratios]
    bin_edges = np.histogram_bin_edges(ratios_only, bins=5)
    colored_output = img_bgr.copy()
    weighted_sum = 0
    total_area = img.shape[0] * img.shape[1]

    for c, ratio in v_ratios:
        bin_index = np.digitize(ratio, bin_edges, right=True) - 1
        bin_index = max(0, min(bin_index, 4))
        color = severity_colors[bin_index]
        cv2.drawContours(colored_output, [c], -1, color, 1)
        weighted_sum += (1 / ratio) * cv2.contourArea(c)

    severity_score = weighted_sum / total_area
    severity_score_10 = map_score_to_10(severity_score)

    return severity_score_10, colored_output


selected_regions = ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']
darkspots_scores = {}

for region in selected_regions:
    if region in patches:
        score, _ = compute_darkspot_score(patches[region])
        darkspots_scores[region] = score
    else:
        print(f"Warning: {region} patch not found in patches dictionary.")


######################################OILINESS#########################################

def get_kmeans_thresh(data, high=True):
    kmeans = KMeans(n_clusters=2, random_state=0).fit(data)
    centers = sorted(kmeans.cluster_centers_.flatten())
    return int(centers[1] if high else centers[0])

def get_kde_thresh(channel_values, high=True):
    data = channel_values.flatten()
    if np.std(data) < 1e-3 or len(np.unique(data)) < 10:
        return int(np.percentile(data, 90 if high else 10))
    try:
        kde = gaussian_kde(data)
        xs = np.linspace(np.min(data), np.max(data), 1000)
        density = kde(xs)
        peak_idx = np.argmax(density)
        if high:
            for i in range(peak_idx, len(xs)):
                if density[i] < density[peak_idx] * 0.5:
                    return int(xs[i])
            return int(xs[-1])
        else:
            for i in range(peak_idx, 0, -1):
                if density[i] < density[peak_idx] * 0.5:
                    return int(xs[i])
            return int(xs[0])
    except np.linalg.LinAlgError:
        return int(np.percentile(data, 90 if high else 10))

def compute_oiliness_score(img_rgb):
    # --- Create mask to exclude purple padding ---
    lower_purple = np.array([120, 0, 120])
    upper_purple = np.array([160, 50, 160])
    purple_mask = cv2.inRange(img_rgb, lower_purple, upper_purple)
    valid_mask = (purple_mask == 0)

    # --- HSV Processing ---
    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
    v, s = img_hsv[:, :, 2], img_hsv[:, :, 1]

    v_valid = v[valid_mask].reshape(-1, 1)
    s_valid = s[valid_mask].reshape(-1, 1)

    v_thresh = int((get_kmeans_thresh(v_valid, high=True) + get_kde_thresh(v_valid, high=True)) / 2)
    s_thresh = int((get_kmeans_thresh(s_valid, high=False) + get_kde_thresh(s_valid, high=False)) / 2)

    v_mask = ((v >= v_thresh) & valid_mask).astype(np.uint8)
    s_mask = ((s <= s_thresh) & valid_mask).astype(np.uint8)
    oil_mask = cv2.bitwise_and(v_mask, s_mask) * 255

    # --- KMeans for Bright Cluster ---
    valid_rgb = img_rgb[valid_mask].reshape(-1, 3)
    kmeans = KMeans(n_clusters=3, random_state=42).fit(valid_rgb)
    centers = kmeans.cluster_centers_
    labels_valid = kmeans.labels_

    labels_full = np.zeros(img_rgb.shape[:2], dtype=np.int32)
    labels_full[valid_mask] = labels_valid
    brightest_idx = np.argmax(np.sum(centers, axis=1))
    bright_mask = ((labels_full == brightest_idx) & valid_mask).astype(np.uint8) * 255

    # --- Combined Overlay ---
    combined = img_rgb.copy()
    combined[(bright_mask == 255) & valid_mask] = [0, 255, 0]      # Green = bright
    combined[(oil_mask == 255) & valid_mask] = [255, 255, 0]       # Yellow = oily
    blended_combined = cv2.addWeighted(img_rgb, 0.6, combined, 0.4, 0)

    # --- Scores ---
    intersection_mask = ((oil_mask == 255) & (bright_mask == 255) & valid_mask)
    union_mask = (((oil_mask == 255) | (bright_mask == 255)) & valid_mask)

    intersection_pixels = np.sum(intersection_mask)
    union_pixels = np.sum(union_mask)
    total_valid_pixels = np.sum(valid_mask)

    overlap_ratio = intersection_pixels / total_valid_pixels if total_valid_pixels > 0 else 0
    jaccard_ratio = intersection_pixels / union_pixels if union_pixels > 0 else 0

    bright_pixels = np.sum(bright_mask == 255)
    bright_coverage_ratio = bright_pixels / total_valid_pixels if total_valid_pixels > 0 else 0

    if bright_coverage_ratio >= 0.7:
        final_score = overlap_ratio
    else:
        final_score = (overlap_ratio ** 0.75) * (jaccard_ratio ** 0.5)

    # --- Final Score Out of 10 ---
    if final_score >= 0.24:
        score_out_of_10 = 10
    elif final_score >= 0.21:
        score_out_of_10 = 9
    elif final_score >= 0.18:
        score_out_of_10 = 8
    elif final_score >= 0.15:
        score_out_of_10 = 7
    elif final_score >= 0.12:
        score_out_of_10 = 6
    elif final_score >= 0.10:
        score_out_of_10 = 5
    elif final_score >= 0.08:
        score_out_of_10 = 4
    elif final_score >= 0.06:
        score_out_of_10 = 3
    elif final_score >= 0.04:
        score_out_of_10 = 2
    else:
        score_out_of_10 = 1

    return score_out_of_10, blended_combined

selected_regions = ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']
oiliness_scores = {}

for region in selected_regions:
    if region in patches:
        score, _ = compute_oiliness_score(patches[region])
        oiliness_scores[region] = score
    else:
        print(f"Warning: {region} patch not found in patches dictionary.")




###############################WRINKLES#########################################

def wrinkle_overlay_single(rgb_image, color=(255, 0, 0)):
    """
    Applies CLAHE + Frangi + Skeletonize on a single RGB image and returns wrinkle overlay.

    Args:
        rgb_image (np.ndarray): Input RGB image (e.g., facial patch).
        color (tuple): RGB color for wrinkle overlay (default = red).

    Returns:
        overlay (np.ndarray): RGB image with wrinkles marked in specified color.
        wrinkle_mask (np.ndarray): Binary mask of final wrinkle skeleton.
    """
    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
    gray = cv2.GaussianBlur(gray, (7,7), sigmaX=2.0)

    # Predefined best CLAHE + Frangi settings
    clahe_settings = [(8.0, (16, 16)), (10.0, (16, 16)), (12.0, (16, 16)), (14.0, (16, 16))]

    skeleton_union = np.zeros_like(gray, dtype=np.uint8)

    for clip, tile in clahe_settings:
        clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=tile)
        clahe_img = clahe.apply(gray)
        fr_input = clahe_img.astype(np.float32) / 255.0
        fr = frangi(fr_input, black_ridges=True, sigmas=[15, 30, 45])
        fr_norm = ((fr - fr.min()) / (np.ptp(fr) + 1e-9) * 255).astype(np.uint8)
        _, fr_bin = cv2.threshold(fr_norm, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        skel = skeletonize(fr_bin > 0).astype(np.uint8)
        skeleton_union = np.logical_or(skeleton_union, skel).astype(np.uint8)

    skeleton_final = skeletonize(skeleton_union > 0).astype(np.uint8)

    # Filter out very short lines (area < 3)
    labeled = measure.label(skeleton_final, connectivity=2)
    props = measure.regionprops(labeled)
    clean_mask = np.zeros_like(skeleton_final, dtype=np.uint8)
    for prop in props:
        if prop.area >= 3:
            clean_mask[labeled == prop.label] = 1

    # Apply overlay on wrinkles
    overlay = rgb_image.copy()
    overlay[clean_mask > 0] = color

    return overlay, clean_mask

# Run wrinkle overlay
selected_regions = [ 'forehead','left_side_eye', 'right_side_eye']
wrinkle_scores = {}
wrinkle_overlays = {}
for region in selected_regions:
    if region in patches:
        overlay_img, wrinkle_mask = wrinkle_overlay_single(patches[region])
        raw_score = np.sum(wrinkle_mask > 0) / wrinkle_mask.size
        score = round(min(raw_score / 0.02, 1.0) * 10)
        wrinkle_scores[region] = score
        wrinkle_overlays[region] = overlay_img
    else:
        print(f"Warning: {region} patch not found in patches dictionary.")



#######################GLOW INDEX##################################

def compute_evenness_smoothness_score(img_rgb):
    def compute_evenness_map(image, cluster_size=20):
        h, w = image.shape[:2]
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        scores = np.zeros((h // cluster_size, w // cluster_size), dtype=np.float32)
        margin = 3 * cluster_size

        for i in range(0, h - cluster_size, cluster_size):
            for j in range(0, w - cluster_size, cluster_size):
                if i < margin or j < margin or i > h - margin - cluster_size or j > w - margin - cluster_size:
                    continue
                patch = image_rgb[i:i+cluster_size, j:j+cluster_size]
                r0, g0, b0 = [np.mean(patch[:, :, k]) for k in range(3)]
                total_diff, count = 0, 0
                for dx, dy in [(0, cluster_size), (cluster_size, 0), (cluster_size, cluster_size), (cluster_size, -cluster_size)]:
                    ni, nj = i + dx, j + dy
                    if 0 <= ni < h - cluster_size and 0 <= nj < w - cluster_size:
                        neighbor = image_rgb[ni:ni+cluster_size, nj:nj+cluster_size]
                        r1, g1, b1 = [np.mean(neighbor[:, :, k]) for k in range(3)]
                        diff = (abs(r0 - r1) + abs(g0 - g1) + abs(b0 - b1)) / 3
                        total_diff += diff
                        count += 1
                if count > 0:
                    scores[i // cluster_size, j // cluster_size] = total_diff / count
        return scores

    def highlight_top_evenness_clusters(image, scores, cluster_size=20, high_pct=90, mid_pct=80):
        # high_thresh = np.percentile(scores[scores > 0], high_pct)
        # mid_thresh = np.percentile(scores[scores > 0], mid_pct)
        valid_scores = scores[scores > 0]
        if len(valid_scores) == 0:
         return image.copy(), 0, 0  # return default if no data

        high_thresh = np.percentile(valid_scores, high_pct)
        mid_thresh = np.percentile(valid_scores, mid_pct)

        h, w = image.shape[:2]
        overlay = image.copy()
        high_scores, mid_scores = [], []

        for i in range(scores.shape[0]):
            for j in range(scores.shape[1]):
                score = scores[i, j]
                if score >= high_thresh:
                    color = (0, 0, 255)
                    high_scores.append(score)
                elif score >= mid_thresh:
                    color = (255, 0, 0)
                    mid_scores.append(score)
                else:
                    continue
                top_left = (j * cluster_size, i * cluster_size)
                bottom_right = (top_left[0] + cluster_size, top_left[1] + cluster_size)
                cv2.rectangle(overlay, top_left, bottom_right, color, 1)

        avg_high = np.mean(high_scores) if high_scores else 0
        avg_mid = np.mean(mid_scores) if mid_scores else 0
        return overlay, avg_high, avg_mid

    def compute_glcm_smoothness(image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        denoised = median(gray, disk(1))
        resized = cv2.resize(denoised, (64, 64))
        glcm = graycomatrix(resized, distances=[1, 2],
                            angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                            symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').mean()

        if contrast <= 7.5:
            score = 10
        elif contrast <= 15:
            score = 9
        elif contrast <= 30:
            score = 8
        elif contrast <= 40:
            score = 7
        elif contrast <= 50:
            score = 6
        elif contrast <= 60:
            score = 5
        elif contrast <= 70:
            score = 4
        elif contrast <= 85:
            score = 3
        elif contrast <= 100:
            score = 2
        else:
            score = 1

        return contrast, score, glcm[:, :, 0, 0]

    # --- Actual Execution ---
    img_bgr=cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    h, w = img_bgr.shape[:2]
    # cluster = int(min(h, w) / 40)
    cluster = max(5, int(min(h, w) / 40))  # Ensure cluster_size is at least 5
    scores = compute_evenness_map(img_bgr, cluster)
    overlay, avg_hi, avg_mid = highlight_top_evenness_clusters(img_bgr, scores, cluster)

    combined = (20 - avg_hi) * 0.3 + 0.7 * (10 - avg_mid)
    evenness_score = max(1, min(10, int(round(10 if combined >= 10 else combined))))  # clamp to [1, 10]

    contrast, smoothness_score, glcm_matrix = compute_glcm_smoothness(img_bgr)

    final_score = round((evenness_score + smoothness_score) / 2, 2)

    return evenness_score, smoothness_score, final_score

glowindex_scores = {}

for name, img_rgb in patches.items():
    even, smooth, final = compute_evenness_smoothness_score(img_rgb)
    glowindex_scores[name] = {
        'glow_index_score': final
    }



###################################DRYNESS#########################################

# --- Texture score ---
def texture(image_bgr):
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l_channel = lab[:, :, 0]
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(l_channel)
    blur1 = cv2.GaussianBlur(enhanced, (3, 3), 0)
    blur2 = cv2.GaussianBlur(enhanced, (9, 9), 0)
    dog = cv2.subtract(blur1, blur2)
    flake_mask = dog > 25
    flake_ratio = np.sum(flake_mask) * 1000 / dog.size * 100 / 1.5 * 10

    if flake_ratio <= 1:
        score = 1
    elif flake_ratio <= 2:
        score = 2
    elif flake_ratio <= 3:
        score = 3
    elif flake_ratio <= 4:
        score = 4
    elif flake_ratio <= 5:
        score = 5
    elif flake_ratio <= 6:
        score = 6
    elif flake_ratio <= 7:
        score = 7
    elif flake_ratio <= 8:
        score = 8
    elif flake_ratio <= 9:
        score = 9
    else:
        score = 10

    return score, flake_ratio

# --- Roughness score ---
def compute_glcm_roughness(image_bgr):
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    denoised = median(gray, disk(1))
    resized = cv2.resize(denoised, (64, 64))
    glcm = graycomatrix(resized, distances=[1, 2],
                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                        symmetric=True, normed=True)
    contrast = graycoprops(glcm, 'contrast').mean()

    if contrast <= 7.5:
        score = 1
    elif contrast <= 15:
        score = 2
    elif contrast <= 30:
        score = 3
    elif contrast <= 40:
        score = 4
    elif contrast <= 50:
        score = 5
    elif contrast <= 60:
        score = 6
    elif contrast <= 70:
        score = 7
    elif contrast <= 85:
        score = 8
    elif contrast <= 100:
        score = 9
    else:
        score = 10

    return score

# --- Wrapper Function ---
def compute_flake_texture_roughness_score(image_rgb):
    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
    texture_score, flake_ratio = texture(image_bgr)
    roughness_score = compute_glcm_roughness(image_bgr)
    final_score = round((texture_score + roughness_score) / 2)

    return final_score

dryness_scores = {}

for name, img_rgb in patches.items():
    final = compute_flake_texture_roughness_score(img_rgb)
    dryness_scores[name] = {
        'dryness_score': final
    }
# NOTE: Due to message size limitations, the full code is too long for a single snippet.
# We'll break it down in the following steps and update this module section by section.

# === Master Entry Function ===
def analyze_image_all_regions(image_np):
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
    patches = process_image(image_bgr)
    results = {}

    dc_scores = {}
    for region in ['left_below_eye', 'right_below_eye']:
        if region in patches:
            dc_scores[region] = compute_image_score(patches[region])
    results['dark_circles'] = dc_scores

    ds_scores = {}
    for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
        if region in patches:
            score, _ = compute_darkspot_score(patches[region])
            ds_scores[region] = score
    results['dark_spots'] = ds_scores

    oil_scores = {}
    for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
        if region in patches:
            score, _ = compute_oiliness_score(patches[region])
            oil_scores[region] = score
    results['oiliness'] = oil_scores

    wrinkle_scores = {}
    for region in ['forehead', 'left_side_eye', 'right_side_eye']:
        if region in patches:
            _, mask = wrinkle_overlay_single(patches[region])
            raw_score = np.sum(mask > 0) / mask.size
            wrinkle_scores[region] = round(min(raw_score / 0.02, 1.0) * 10)
    results['wrinkles'] = wrinkle_scores

    glow_scores = {}
    for name, img in patches.items():
        even, smooth, final = compute_evenness_smoothness_score(img)
        glow_scores[name] = final
    results['glow_index'] = glow_scores

    dryness_scores = {}
    for name, img in patches.items():
        dryness_scores[name] = compute_flake_texture_roughness_score(img)
    results['dryness'] = dryness_scores

    
    # return results
        # Print all results clearly
    print("\n--- Final Region-wise Scores ---", flush=True)
    for category, region_scores in results.items():
        print(f"\n{category.upper()}:", flush=True)
    for region, score in region_scores.items():
        print(f"  {region}: {score}", flush=True)


    return results
