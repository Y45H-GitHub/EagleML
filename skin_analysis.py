# -*- coding: utf-8 -*-
"""skin_analysis.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YLiqG7bsyeEEdcoqVSiXSCmsq12OOtKo
"""

# === All helper functions and full analysis code from Word file goes below ===

# [PASTE COMPLETE CODE FROM WORD FILE HERE - all functions, patch logic, scores, etc.]

# Install and import dependencies


# --- Imports ---
import cv2
import numpy as np
import mediapipe as mp
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
import torch
from torchvision.utils import save_image
from Models.modelv2 import MobileHairNetV2
import math
import os
from PIL import Image
from sklearn.cluster import KMeans
from scipy.stats import gaussian_kde
from skimage.filters import frangi
from skimage import img_as_float
from skimage.morphology import skeletonize
from skimage.color import rgb2gray
from skimage.filters.rank import median
from skimage.morphology import disk
from skimage.feature import graycomatrix, graycoprops
from skimage.filters import median
from skimage import measure
from collections import defaultdict

import time
import functools

def timer(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        t0 = time.perf_counter()
        result = func(*args, **kwargs)
        elapsed = time.perf_counter() - t0
        print(f"⏱️ {func.__name__} took {elapsed:.3f} sec")
        return result
    return wrapper



# image_path = r"C:\Users\Yash\Desktop\face_app_final\myface.jpg"  # Path to your image

####################################FOREHEAD PATCH#######################################
# !git clone https://github.com/wonbeomjang/mobile-hair-segmentation-pytorch.git
# %cd mobile-hair-segmentation-pytorch

# Initialize MediaPipe FaceMesh
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

# shrink_ratio
shrink_ratio_below_eyes = 0.75
shrink_ratio_side_eyes = 0.75
shrink_ratio_nose = 1.0
shrink_ratio_cheeks = 0.75
shrink_ratio_chin = 0.80
# shrink_ratio_below_cheek = 0.80


# To Balance image
left_most_landmark  = 130
right_most_landmark = 359

TARGET_SIZE = 224

# Indices for each
right_below_eye_indices = [126, 101, 116, 143, 25, 472, 112]
left_below_eye_indices  = [355, 330, 345, 372, 255, 477, 341]

right_cheek_indices = [120,142,206,207,123,116,117,118,119,111]
left_cheek_indices  = [349,371,426,427,352,345,346,347,348,340]

RIGHT_EYE_SIDE_INDICES = [27,46,156,118,24]
LEFT_EYE_SIDE_INDICES  = [257,276,383,347,254]
RIGHT_EYE_MASK_INDICES = [226, 113, 30, 27, 56, 190, 112, 23, 25]
LEFT_EYE_MASK_INDICES  = [446, 342, 260, 257, 286, 414, 341, 253, 255]

nose_indices = [4, 420, 399, 351, 122, 174, 198, 279, 49]            #[115, 4, 344, 420, 399, 351, 6,122, 174, 198]
chin_indices = [83,313,418,262,199,32,194]

# left_below_cheek_indices = [427,287,367,433]
# right_below_cheek_indices = [207,57,138,213]

# get_angle_function
def get_rotation_angle(p1, p2):
    dx = p2[0] - p1[0]
    dy = p2[1] - p1[1]
    angle = math.degrees(math.atan2(dy, dx))
    return angle

# return rotated image
def rotate_image(image, angle):
    h, w = image.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)

    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])
    new_w = int((h * sin) + (w * cos))
    new_h = int((h * cos) + (w * sin))

    M[0, 2] += (new_w / 2) - center[0]
    M[1, 2] += (new_h / 2) - center[1]

    rotated = cv2.warpAffine(image, M, (new_w, new_h), borderValue=(255, 255, 255))
    return rotated, M


# --- Hair segmentation on cropped image ---
def get_hair_mask(image_path, output_path="hair_mask.png"):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    net = MobileHairNetV2().to(device)
    image = Image.open(image_path).convert("RGB")
    orig_size = image.size
    image_tensor = TF.to_tensor(image).to(device)
    image_tensor = TF.resize(image_tensor, [224, 224])
    image_tensor = TF.normalize(image_tensor, [0.5]*3, [0.5]*3)
    with torch.no_grad():
        mask = net(image_tensor.unsqueeze(0)).argmax(dim=1)
        mask = TF.resize(mask, list(orig_size[::-1])).squeeze()
    save_image(mask.float(), output_path)
    return output_path

# --- Define patch using averaged landmarks ---
def extract_forehead_patch_above_nose(
    full_img, cropped_above_img, hair_mask_np, landmark_list,
    idx_left_pair, idx_right_pair, h,nose_y,buffer_px=5,
    min_ratio=0.4, max_attempts=5, shrink_factor=0.2
):
    img_width = cropped_above_img.width
    img_height = cropped_above_img.height

    def avg_xy(idx_pair):
        x = (landmark_list[idx_pair[0]].x + landmark_list[idx_pair[1]].x) / 2
        y = (landmark_list[idx_pair[0]].y + landmark_list[idx_pair[1]].y) / 2
        return int(x * img_width), int(y * h)

    x1, y1 = avg_xy(idx_left_pair)
    x2, y2 = avg_xy(idx_right_pair)

    x_left_orig = min(x1, x2)
    x_right_orig = max(x1, x2)
    y_bottom = min(y1, y2)
    y_bottom = min(y_bottom, img_height)

    # --- Step 1: Initial patch_top ---
    def compute_patch_top(xl, xr):
        patch_top = 0
        for x in range(xl, xr):
            column = hair_mask_np[:, x]
            hair_pixels = np.where((column == 1) & (np.arange(len(column)) < y_bottom))[0]
            if len(hair_pixels) > 0:
                lowest_y = hair_pixels[-1]
                patch_top = max(patch_top, lowest_y + buffer_px)
        return min(patch_top, y_bottom - 1)

    patch_top = compute_patch_top(x_left_orig, x_right_orig)

    x_left = x_left_orig
    x_right = x_right_orig

    # # --- Step 2: Adjust width if aspect ratio too low ---
    # attempt = 0
    # while attempt < max_attempts:
    #     patch_height = y_bottom - patch_top
    #     patch_width = x_right - x_left
    #     aspect_ratio = patch_height / patch_width

    #     if aspect_ratio >= min_ratio:
    #         break

    #     # Shrink width
    #     shrink_by = int(shrink_factor * patch_width)
    #     if shrink_by < 2:
    #         break

    #     center = (x_left + x_right) // 2
    #     new_half = (patch_width - shrink_by) // 2
    #     x_left = max(center - new_half, 0)
    #     x_right = min(center + new_half, img_width)

    #     patch_top = compute_patch_top(x_left, x_right)
    #     attempt += 1
    #     print(f"⚠ Reduced width attempt {attempt} | New aspect ratio: {aspect_ratio:.2f}")

        # --- Step 3: Extend width left and right within landmark bounds (only if hair is not inside box) ---
    while x_left > x_left_orig:
        x_new = x_left - 1
        sub_mask = hair_mask_np[patch_top:y_bottom, x_new:x_right]
        if np.any(sub_mask == 1):
            break
        x_left = x_new

    while x_right < x_right_orig:
        x_new = x_right + 1
        sub_mask = hair_mask_np[patch_top:y_bottom, x_left:x_new]
        if np.any(sub_mask == 1):
            break
        x_right = x_new

    # --- Step 4: Extend patch_top upward (only if no hair comes inside box) ---
    while patch_top > 0:
        y_new = patch_top - 1
        sub_mask = hair_mask_np[y_new:y_bottom, x_left:x_right]
        if np.any(sub_mask == 1):
            break
        patch_top = y_new

    # Final crop
    patch = cropped_above_img.crop((x_left, patch_top, x_right, y_bottom))
    return patch, (x_left, patch_top, x_right, y_bottom)

# extract patches for all except side_eye
def extract_patch(image, landmark_points, shrink_ratio=0.8):
    h, w = image.shape[:2]
    points = np.array([[int(pt.x * w), int(pt.y * h)] for pt in landmark_points], np.int32)

    x_min, y_min = points.min(axis=0)
    x_max, y_max = points.max(axis=0)

    box_w = x_max - x_min
    box_h = y_max - y_min

    shrink_w = int(box_w * shrink_ratio)
    shrink_h = int(box_h * shrink_ratio)

    center_x = (x_min + x_max) // 2
    center_y = (y_min + y_max) // 2

    x1 = max(0, center_x - shrink_w // 2)
    y1 = max(0, center_y - shrink_h // 2)
    x2 = min(w, center_x + shrink_w // 2)
    y2 = min(h, center_y + shrink_h // 2)

    return image[y1:y2, x1:x2]

# extract patch for only side-eye
def extract_patch_side_eye(image, landmark_points, eye_mask_points=None, shrink_ratio=0.8):
    h, w = image.shape[:2]
    points = np.array([[int(pt.x * w), int(pt.y * h)] for pt in landmark_points], np.int32)

    x_min, y_min = points.min(axis=0)
    x_max, y_max = points.max(axis=0)
    box_w = x_max - x_min
    box_h = y_max - y_min

    shrink_w = int(box_w * shrink_ratio)
    shrink_h = int(box_h * shrink_ratio)
    center_x = (x_min + x_max) // 2
    center_y = (y_min + y_max) // 2

    x_start = max(0, center_x - shrink_w // 2)
    y_start = max(0, center_y - shrink_h // 2)
    x_end = min(w, center_x + shrink_w // 2)
    y_end = min(h, center_y + shrink_h // 2)

    patch = image[y_start:y_end, x_start:x_end].copy()

    if patch.size == 0 or patch.ndim != 3 or patch.shape[2] != 3:
        print("⚠ Skipping invalid patch:", patch.shape)
        return np.zeros((TARGET_SIZE, TARGET_SIZE, 3), dtype=np.uint8)

    if eye_mask_points:
        mask = np.zeros(patch.shape[:2], dtype=np.uint8)
        eye_poly = np.array([[int(pt.x * w) - x_start, int(pt.y * h) - y_start] for pt in eye_mask_points], np.int32)
        cv2.fillPoly(mask, [eye_poly], 255)
        patch = cv2.inpaint(patch, mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)

        # Begin corrected white-pixel filling logic
        white_mask = np.all(patch == 255, axis=2)
        patch_float = patch.astype(np.float32)
        h_patch, w_patch = patch.shape[:2]

        x_color_avg = {}
        y_color_avg = {}

        # X-based skin sampling (same column, up to 3 above and 3 below each white pixel)
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    color_sum = np.zeros(3)
                    count = 0
                    for offset in range(1, 4):
                        above_y = y - offset
                        below_y = y + offset
                        if 0 <= above_y < h_patch and not white_mask[above_y, x]:
                            color_sum += patch_float[above_y, x]
                            count += 1
                        if 0 <= below_y < h_patch and not white_mask[below_y, x]:
                            color_sum += patch_float[below_y, x]
                            count += 1
                    if count > 0:
                        x_color_avg[(y, x)] = color_sum / count

        # Y-based skin sampling (same row, up to 3 left and right of each white pixel)
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    color_sum = np.zeros(3)
                    count = 0
                    for offset in range(1, 4):
                        left_x = x - offset
                        right_x = x + offset
                        if 0 <= left_x < w_patch and not white_mask[y, left_x]:
                            color_sum += patch_float[y, left_x]
                            count += 1
                        if 0 <= right_x < w_patch and not white_mask[y, right_x]:
                            color_sum += patch_float[y, right_x]
                            count += 1
                    if count > 0:
                        y_color_avg[(y, x)] = color_sum / count

        # Apply average of both x and y-based values
        for y in range(h_patch):
            for x in range(w_patch):
                if white_mask[y, x]:
                    col_x = x_color_avg.get((y, x))
                    col_y = y_color_avg.get((y, x))
                    if col_x is not None and col_y is not None:
                        patch[y, x] = ((col_x + col_y) / 2).astype(np.uint8)
                    elif col_x is not None:
                        patch[y, x] = col_x.astype(np.uint8)
                    elif col_y is not None:
                        patch[y, x] = col_y.astype(np.uint8)
        # End white fill

    # Resize patch while keeping aspect ratio, no padding
    ph, pw = patch.shape[:2]
    if ph >= pw:
        new_h = TARGET_SIZE
        new_w = int(pw * (TARGET_SIZE / ph))
    else:
        new_w = TARGET_SIZE
        new_h = int(ph * (TARGET_SIZE / pw))

    patch = cv2.resize(patch, (new_w, new_h), interpolation=cv2.INTER_AREA)
    return patch


####Extract patch for eye-side eye wrinkles
def extract_and_mask_eyes_from_indices(image, landmarks, eye_indices):
    """
    Extracts and masks eye regions using landmark indices.
    Returns both the eye images (with magenta fill) and the binary masks.
    """
    def process_eye(outer_ids, inner_ids):
        outer_pts = np.array([landmarks[i] for i in outer_ids], dtype=np.int32)
        inner_pts = np.array([landmarks[i] for i in inner_ids], dtype=np.int32)

        x, y, w, h = cv2.boundingRect(outer_pts)
        eye_roi = image[y:y+h, x:x+w].copy()

        # Offset landmarks for ROI
        inner_offset = inner_pts - [x, y]

        # Create mask for inner eye region
        mask = np.ones((h, w), dtype=np.uint8) * 255
        cv2.fillPoly(mask, [inner_offset], 0)

        # Fill inner region with magenta in the eye image
        eye_roi[mask == 0] = [255, 0, 255]  # Magenta in BGR

        return eye_roi, mask

    left_eye_img, left_eye_mask = process_eye(eye_indices["left_eye_outer"], eye_indices["left_eye_inner"])
    right_eye_img, right_eye_mask = process_eye(eye_indices["right_eye_outer"], eye_indices["right_eye_inner"])

    return (left_eye_img, left_eye_mask), (right_eye_img, right_eye_mask)



# Main Process
@timer
def process_image(image):
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(image_rgb)
    results = face_mesh.process(image_rgb)

    if not results.multi_face_landmarks:
        print("❌ Face not detected in input image")
        return {}

    landmarks = results.multi_face_landmarks[0].landmark
    h, w, _ = image.shape

    pt1 = (int(landmarks[left_most_landmark].x * w), int(landmarks[left_most_landmark].y * h))
    pt2 = (int(landmarks[right_most_landmark].x * w), int(landmarks[right_most_landmark].y * h))

    # Rotate image
    angle = get_rotation_angle(pt1, pt2)
    rotated_image,M = rotate_image(image, angle)

    # Detect landmarks on rotated image
    rotated_rgb = cv2.cvtColor(rotated_image, cv2.COLOR_BGR2RGB)
    rotated_img_pil = Image.fromarray(rotated_rgb)
    rotated_results = face_mesh.process(rotated_rgb)
    if not rotated_results.multi_face_landmarks:
        print("❌ Face not detected after rotation")
        return {}

    rotated_landmarks = rotated_results.multi_face_landmarks[0].landmark


##############Left & Right Eye###################
    # ---- Eye masks (with magenta fill) ----
    eye_indices = {
        "left_eye_outer": [257, 445, 383, 372, 347, 349, 453, 413, 286],
        "left_eye_inner": [463, 414, 286, 257, 260, 359, 255, 253, 341],
        "right_eye_outer": [223, 222, 189, 233, 120, 117, 143, 225],
        "right_eye_inner": [226, 30, 27, 28, 56, 243, 23, 110]
    }

    # Get landmark coords as (x, y) for current image
    h_rot, w_rot, _ = rotated_image.shape
    landmark_xy = [(int(pt.x * w_rot), int(pt.y * h_rot)) for pt in rotated_landmarks]

    (left_eye_img, left_eye_mask), (right_eye_img, right_eye_mask) = extract_and_mask_eyes_from_indices(
        rotated_image, landmark_xy, eye_indices
    )



##############forehead landmarks##################
    rh, rw, _ = rotated_rgb.shape
    nose_y = int(rotated_landmarks[9].y * rh)

    # --- Crop image above nose ---
    img_above_np = rotated_rgb[:nose_y, :, :]
    img_above = Image.fromarray(img_above_np)
    img_above.save("img_above.png")

    # --- Segment hair on upper part only ---
    mask_path = get_hair_mask("img_above.png", "hair_mask_above.png")
    hair_mask = Image.open(mask_path).convert("L")
    hair_mask = hair_mask.point(lambda x: 1 if x > 128 else 0)
    hair_mask_np = np.array(hair_mask)


    # --- Landmark pairs for patch corners ---
    idx_left_pair = (66, 69)
    idx_right_pair = (299,296)

    # --- Extract forehead patch ---
    forehead_patch, coords = extract_forehead_patch_above_nose(
        full_img=rotated_img_pil,
        cropped_above_img=img_above,
        hair_mask_np=hair_mask_np,
        landmark_list=rotated_landmarks,
        idx_left_pair=idx_left_pair,
        idx_right_pair=idx_right_pair,
        buffer_px=5,
        min_ratio=0.3,
        h=rotated_rgb.shape[0],  # or simply h if already defined
        nose_y=nose_y
    )


    # Extract cheek patches
    right_cheek = extract_patch(rotated_image, [rotated_landmarks[i] for i in right_cheek_indices], shrink_ratio_cheeks)
    left_cheek  = extract_patch(rotated_image, [rotated_landmarks[i] for i in left_cheek_indices], shrink_ratio_cheeks)

    right_below_eye = extract_patch(rotated_image, [rotated_landmarks[i] for i in right_below_eye_indices], shrink_ratio_below_eyes)
    left_below_eye  = extract_patch(rotated_image, [rotated_landmarks[i] for i in left_below_eye_indices], shrink_ratio_below_eyes)

    nose = extract_patch(rotated_image, [rotated_landmarks[i] for i in nose_indices], shrink_ratio_nose)
    chin = extract_patch(rotated_image, [rotated_landmarks[i] for i in chin_indices], shrink_ratio_chin)

    # right_side_eye = extract_patch_side_eye(rotated_image, [landmarks[i] for i in RIGHT_EYE_SIDE_INDICES],
    #                 eye_mask_points=[landmarks[i] for i in RIGHT_EYE_MASK_INDICES], shrink_ratio=shrink_ratio_side_eyes)

    # left_side_eye  = extract_patch_side_eye(rotated_image, [landmarks[i] for i in LEFT_EYE_SIDE_INDICES],
    #                 eye_mask_points=[landmarks[i] for i in LEFT_EYE_MASK_INDICES], shrink_ratio=shrink_ratio_side_eyes)


    # right_below_cheek = extract_patch(rotated_image, [rotated_landmarks[i] for i in right_below_cheek_indices], shrink_ratio_below_cheek)
    # left_below_cheek  = extract_patch(rotated_image, [rotated_landmarks[i] for i in left_below_cheek_indices], shrink_ratio_below_cheek)


    # Convert to RGB
    right_cheek_rgb = cv2.cvtColor(right_cheek, cv2.COLOR_BGR2RGB)
    left_cheek_rgb = cv2.cvtColor(left_cheek, cv2.COLOR_BGR2RGB)
    right_below_eye_rgb = cv2.cvtColor(right_below_eye, cv2.COLOR_BGR2RGB)
    left_below_eye_rgb = cv2.cvtColor(left_below_eye, cv2.COLOR_BGR2RGB)
    nose_rgb = cv2.cvtColor(nose, cv2.COLOR_BGR2RGB)
    chin_rgb = cv2.cvtColor(chin, cv2.COLOR_BGR2RGB)
    # right_side_eye_rgb = cv2.cvtColor(right_side_eye, cv2.COLOR_BGR2RGB)
    # left_side_eye_rgb = cv2.cvtColor(left_side_eye, cv2.COLOR_BGR2RGB)
    left_eye_rgb = cv2.cvtColor(left_eye_img, cv2.COLOR_BGR2RGB)
    right_eye_rgb = cv2.cvtColor(right_eye_img, cv2.COLOR_BGR2RGB)
    # right_below_cheek_rgb = cv2.cvtColor(right_below_cheek, cv2.COLOR_BGR2RGB)
    # left_below_cheek_rgb = cv2.cvtColor(left_below_cheek, cv2.COLOR_BGR2RGB)

    forehead_rgb = np.array(forehead_patch)  # Convert PIL to NumPy RGB

    return {
        'right_cheek': right_cheek_rgb,
        'left_cheek': left_cheek_rgb,
        'right_below_eye': right_below_eye_rgb,
        'left_below_eye': left_below_eye_rgb,
        'nose': nose_rgb,
        'chin': chin_rgb,
        # 'right_side_eye': right_side_eye_rgb,
        # 'left_side_eye': left_side_eye_rgb,
        'forehead': forehead_rgb,
        'forehead_coords': coords,
        'rotation_matrix': M, # <--- return M too

        'left_eye': (left_eye_rgb, left_eye_mask),
        'right_eye': (right_eye_rgb, right_eye_mask),
    }


# image_bgr = cv2.imread(image_path)
# patches = process_image(image_bgr)

# # print(patches['right_below_eye'].shape)
# plt.imshow(patches['forehead'])
# plt.axis('off')




##################HIDDEN DARKSPOTS############################
# ====== SHARPENING KERNELS ======
basic_kernel = np.array([[0, -1, 0],
                         [-1, 5, -1],
                         [0, -1, 0]], dtype=np.float32)

strong_kernel = np.array([[0, -1, 0],
                          [-1, 5, -1],
                          [0, -1, 0]], dtype=np.float32)

# ====== SUPPORT FUNCTIONS ======
def compute_alpha(l_channel):
    mean_l = np.mean(l_channel)
    std_l = np.std(l_channel)
    alpha_brightness = 1 - (mean_l / 255)
    alpha_contrast = 1 - (std_l / 64)
    alpha = np.clip(0.5 * alpha_brightness + 0.5 * alpha_contrast, 0, 1)
    return alpha

def get_adaptive_kernel(alpha):
    return (1 - alpha) * basic_kernel + alpha * strong_kernel

def process_with_kernel(l_channel, kernel):
    sharpened = cv2.filter2D(l_channel, -1, kernel)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    return clahe.apply(sharpened)

# ====== MAIN PROCESSING FUNCTION ======
def enhance_dry_patch_single(image_path):
    """
    Enhances dryness-relevant features in a single image and returns the result as an RGB numpy array.
    """
    img = cv2.imread(image_path)
    if img is None:
        raise ValueError(f" Could not read image: {image_path}")

    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)

    alpha = compute_alpha(l)
    adaptive_kernel = get_adaptive_kernel(alpha)

    l_adaptive = process_with_kernel(l, adaptive_kernel)

    lab_mod = cv2.merge([l_adaptive, a, b])
    final_bgr = cv2.cvtColor(lab_mod, cv2.COLOR_LAB2BGR)
    final_rgb = cv2.cvtColor(final_bgr, cv2.COLOR_BGR2RGB)
    return final_rgb

# # Path to single image
# image_path = "/content/myface3.jpg"

# Get enhanced image (RGB)
# enhanced_rgb = enhance_dry_patch_single(image_path)




################Dark Circle###################
# --- Score Mapping ---
# def convert_to_score_10(score):
#     if score >= 85: return 10
#     elif score >= 75: return 9
#     elif score >= 65: return 8
#     elif score >= 60: return 7
#     elif score >= 55: return 6
#     elif score >= 50: return 5
#     elif score >= 45: return 4
#     elif score >= 35: return 3
#     elif score >= 25: return 2
#     else: return 1

def compress_score_dc(value):
    # if value <= 22:
    #     return 1
    # elif value >= 86:
    #     return 9

    # Linear scaling from range 22–86 → 1–9
    scaled = 1 + (value - 22) * (8 / (86 - 22))
    if scaled > 9.5:
        return 9.5
    if scaled < 1:
      return 1

    return round(scaled, 2)



# --- KDE Threshold Helper ---
def adaptive_kde_threshold(channel_data, fraction=0.10):
    flat = channel_data.flatten()
    flat = flat[flat > 0]
    kde = gaussian_kde(flat)
    x = np.linspace(np.min(flat), np.max(flat), 256)
    y = kde(x)
    cdf = np.cumsum(y)
    cdf /= cdf[-1]
    idx = np.where(cdf >= fraction)[0][0]
    return x[idx]

# --- Main Function ---
import numpy as np
import cv2
from sklearn.cluster import KMeans
from scipy.stats import gaussian_kde
from skimage.color import rgb2gray
from skimage.filters import frangi
from skimage import img_as_float
from skimage.morphology import skeletonize

@timer
def compute_darkcircle_score(img_rgb, eps=1e-5):
    img_np = np.array(img_rgb)
    H, W = img_np.shape[:2]
    img_bgr = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)

    # Build exclusion mask
    exclusion_mask = np.ones((H, W), dtype=np.uint8)
    buffer_w, buffer_h = W // 6, H // 3
    exclusion_mask[H-buffer_h:, :buffer_w] = 0
    exclusion_mask[H-buffer_h:, W-buffer_w:] = 0

    # --- LAB Redness ---
    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a, _ = cv2.split(lab)
    a_prime = a.astype(np.int16) - 128
    a_norm = a_prime / (l.astype(np.float32) + eps)
    valid = (a_norm > 0) & (exclusion_mask > 0)
    if np.any(valid):
        a_thresh = np.percentile(a_norm[valid], 70)
        red_mask = valid & (a_norm > a_thresh)
        non_red = (exclusion_mask > 0) & ~red_mask
        red_mean = np.mean(a_norm[red_mask]) if np.any(red_mask) else 0.0
        non_red_mean = np.mean(a_norm[non_red]) if np.any(non_red) else eps
        red_severity = (red_mean - non_red_mean) / non_red_mean
    else:
        red_severity = 0.0

    # --- LAB Blueness ---
    b = lab[:, :, 2]
    b_vals = b[exclusion_mask > 0]
    if b_vals.size:
        b_thresh = adaptive_kde_threshold(b_vals, 0.10)
        blue_mask = (b <= int(b_thresh)) & (exclusion_mask > 0)
        non_blue = (exclusion_mask > 0) & ~blue_mask
        blue_mean = np.mean(b[blue_mask]) if np.any(blue_mask) else 0.0
        non_blue_mean = np.mean(b[non_blue]) if np.any(non_blue) else eps
        blue_severity = (non_blue_mean - blue_mean) / (blue_mean + eps)
    else:
        blue_severity = 0.0

    # --- Darkness (HSV V-channel) ---
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    v = hsv[:, :, 2]
    v_masked = v[exclusion_mask > 0].flatten()
    if v_masked.size:
        kde = gaussian_kde(v_masked)
        v_vals = np.linspace(0, 255, 256)
        kde_vals = kde(v_vals)
        diffs = np.diff(kde_vals)
        cond = (np.hstack(([False], diffs[:-1] < 0)) &
                np.hstack((diffs[1:] > 0, [False])))
        valleys = np.where(cond)[0]
    else:
        valleys = []

    if len(valleys) >= 2:
        v_thresh1, v_thresh2 = int(v_vals[valleys[0]]), int(v_vals[valleys[1]])
    else:
        # fallback to KMeans
        km = KMeans(n_clusters=3, random_state=0).fit(v_masked.reshape(-1, 1))
        centers = sorted(km.cluster_centers_.flatten())
        v_thresh1, v_thresh2 = int(centers[0]), int(centers[1])

    thresholds = {
        'low':      {'min': v_thresh2 + 1, 'max': 255},
        'moderate': {'min': v_thresh1 + 1, 'max': v_thresh2},
        'high':     {'min': 0, 'max': v_thresh1}
    }
    level_masks = {
        lvl: ((v >= cfg['min']) & (v <= cfg['max']) & (exclusion_mask > 0))
        for lvl, cfg in thresholds.items()
    }

    # Safely compute medians
    medians = {}
    for lvl in ['low','moderate','high']:
        vals = v[level_masks[lvl]]
        medians[lvl] = np.median(vals) if vals.size else eps

    v_low, v_mid, v_high = medians['low'], medians['moderate'], medians['high']
    # guard against zero
    darkness_severity = (
        (v_low / (v_high + eps)) +
        (v_mid / (v_high + eps)) +
        (v_low / (v_mid + eps))
    )

    # Area ratios
    high_area = np.sum(level_masks['high'])
    moderate_area = np.sum(level_masks['moderate'])
    low_area = np.sum(level_masks['low'])
    area_ratio = (high_area + moderate_area) / max(high_area + moderate_area + low_area, 1)

    # --- Vesselness ---
    gray = rgb2gray(img_np)
    vesselness = frangi(img_as_float(gray))
    dark_mask = level_masks['high'] | level_masks['moderate']
    vessel_masked = vesselness * dark_mask
    if np.any(vessel_masked > 0):
        thresh_v = np.percentile(vessel_masked[vessel_masked > 0], 90)
        vessel_bin = vessel_masked > thresh_v
        skeleton = skeletonize(vessel_bin)
        length = skeleton.sum()
        mean_val = vessel_masked[vessel_bin].mean() if np.any(vessel_bin) else 0.0
        vessel_score = length * mean_val / (2*(H + W) + eps)
    else:
        vessel_score = 0.0

    # --- Final Score on 0–10 scale ---
    final = 40 * (
        0.8 * (darkness_severity/6)**0.55 +
        0.05 * (red_severity/3) +
        0.05 * (blue_severity/2) +
        0.1 * (vessel_score/0.6)
    ) * area_ratio * darkness_severity * (10/9)

    # compress_score_dc should map to 0–10; protect against NaN
    score_10 = compress_score_dc(final) if not np.isnan(final) else 0.0

    return float(score_10)




# Provide path to your local image (e.g., in Colab or locally)

# Extract left and right below-eye patches
# selected_regions = ['left_below_eye', 'right_below_eye']
# darkcircle_scores = {}

# for region in selected_regions:
#     if region in patches:
#         score = compute_darkcircle_score(patches[region])
#         darkcircle_scores[region] = score
#     else:
#         print(f"Warning: {region} patch not found in patches dictionary.")


##########################DARK SPOTS##############################
@timer
def compute_darkspot_score(img):
    intervals = {
        'bound': {'min': 100, 'max': 255},
        'low': {'min': 150, 'max': 255},
        'mid': {'min': 180, 'max': 255},
        'high': {'min': 200, 'max': 255},
    }

    # severity_colors = [(0, 0, 255), (128, 0, 128), (255, 0, 0), (0, 255, 0), (0, 0, 0)]  # Red → Black

    def find_clean_contours(mask, shape):
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        cleaned = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)
        contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        return [cnt for cnt in contours if not is_touching_border(cnt, shape)]

    def is_touching_border(contour, shape):
        h, w = shape[:2]
        for pt in contour:
            x, y = pt.ravel()
            if x <= 1 or y <= 1 or x >= w - 2 or y >= h - 2:
                return True
        return False

    def is_inside(inner, outer):
        inner_pts = inner.reshape(-1, 2)
        total = len(inner_pts)
        outside = sum(cv2.pointPolygonTest(outer, (float(x), float(y)), False) <= 0 for x, y in inner_pts)
        return (outside / total) <= 0.3

    def merge_contours(inner, outer):
        merged_inner = []
        used = set()
        for oc in outer:
            grouped = []
            for j, ic in enumerate(inner):
                if j not in used and is_inside(ic, oc):
                    grouped.append(ic)
                    used.add(j)
            if len(grouped) > 1:
                merged_inner.append(oc)
        for j in sorted(used, reverse=True):
            del inner[j]
        inner.extend(merged_inner)

    def filter_by_area(contours, bins):
        areas = [cv2.contourArea(c) for c in contours]
        if len(areas) < 2:
            return contours
        thresholds = np.histogram_bin_edges(areas, bins=bins)
        return [c for c in contours if cv2.contourArea(c) > thresholds[1]]

    # === Interpolation Functions ===
    def linear_interpolate_severity(score):
        points = [
            (0.06, 2), (0.08, 3), (0.10, 4), (0.12, 5), (0.15, 6),
            (0.18, 7), (0.21, 8), (0.24, 9), (0.27, 9.5)
        ]
        for i in range(len(points) - 1):
            x0, y0 = points[i]
            x1, y1 = points[i + 1]
            if x0 <= score <= x1:
                return y0 + (score - x0) * (y1 - y0) / (x1 - x0)
        return 1.0 if score < points[0][0] else 10.0

    def linear_interpolate_dev(ratio):
        points = [
            (0.7, 9.5), (0.75, 9), (0.80, 8), (0.85, 7), (0.90, 6),
            (0.925, 5), (0.95, 4), (0.975, 3), (1.0, 2)
        ]
        for i in range(len(points) - 1):
            x0, y0 = points[i]
            x1, y1 = points[i + 1]
            if x0 <= ratio <= x1:
                return y0 + (ratio - x0) * (y1 - y0) / (x1 - x0)
        return 10.0 if ratio < points[0][0] else 1.0

    def linear_interpolate_acne(score):
        points = [
            (0.0005, 2), (0.001, 4), (0.002, 6),
            (0.003, 8), (0.004, 10)
        ]
        for i in range(len(points) - 1):
            x0, y0 = points[i]
            x1, y1 = points[i + 1]
            if x0 <= score <= x1:
                return y0 + (score - x0) * (y1 - y0) / (x1 - x0)
        return 1.0 if score < points[0][0] else 10.0


    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)
    v_channel = hsv[:, :, 2]

    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)
    l, a_lab, b_lab = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    l_clahe = clahe.apply(l)
    lab_clahe = cv2.merge((l_clahe, a_lab, b_lab))
    img_enhanced = cv2.cvtColor(lab_clahe, cv2.COLOR_LAB2BGR)

    gray = cv2.cvtColor(img_enhanced, cv2.COLOR_BGR2GRAY)
    inverted = 255 - gray
    inv_clahe = clahe.apply(inverted)

    contours_by_label = {
        label: find_clean_contours(cv2.inRange(inv_clahe, cfg['min'], cfg['max']), img.shape)
        for label, cfg in intervals.items()
    }

    red, blue, green, bound = contours_by_label['high'], contours_by_label['mid'], contours_by_label['low'], contours_by_label['bound']
    merge_contours(red, blue)
    merge_contours(blue, green)
    merge_contours(red, green)

    all_contours = (
        filter_by_area(red, 50) +
        filter_by_area(blue, 50) +
        filter_by_area(green, 50) +
        filter_by_area(bound, 20)
    )

    mask_all = np.zeros_like(v_channel, dtype=np.uint8)
    for c in all_contours:
        cv2.drawContours(mask_all, [c], -1, 255, -1)
    healthy_skin_V = np.median(v_channel[mask_all == 0])

    filtered_final = []
    for i, c1 in enumerate(all_contours):
        nested = False
        for j, c2 in enumerate(all_contours):
            if i != j and is_inside(c1, c2):
                if cv2.contourArea(c1) / cv2.contourArea(c2) > 0.25:
                    nested = True
                    break
        if not nested:
            filtered_final.append(c1)

    final_cleaned = []
    for i, c_outer in enumerate(filtered_final):
        area_outer = cv2.contourArea(c_outer)
        inner_sum = sum(cv2.contourArea(c_inner) for j, c_inner in enumerate(filtered_final)
                        if i != j and is_inside(c_inner, c_outer))
        if inner_sum / (area_outer + 1e-5) < 0.6:
            final_cleaned.append(c_outer)

    h, s, v = cv2.split(hsv)
    a = cv2.split(cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB))[1]
    acne_contours = []
    results = []

    for i, c in enumerate(final_cleaned):
        mask = np.zeros_like(v, dtype=np.uint8)
        cv2.drawContours(mask, [c], -1, 255, -1)
        acne_mask = (((h < 11.5) | (h > 0)) & (s > 70) & (s < 145) & (a > 142) & (a < 200) & (mask == 255)).astype(np.uint8)
        dark_mask = ((h > 8) & (h < 15) & (s > 50) & (s < 155) & (a > 100) & (a < 155) & (mask == 255)).astype(np.uint8)
        acne_score = np.sum(acne_mask)
        dark_score = np.sum(dark_mask)
        total = acne_score + dark_score + 1e-5
        label = "acne" if acne_score > dark_score else "dark spot"
        if label == "acne":
            acne_contours.append(c)
        results.append((i + 1, label, max(acne_score, dark_score) / total))

    acne_area = sum(cv2.contourArea(c) for c in acne_contours)
    total_area = img.shape[0] * img.shape[1]
    acne_score = 2.4*(acne_area) / (total_area + 1e-5)
    # acne_severity = round(linear_interpolate_acne(acne_score), 2)
    if acne_score > 1:
             acne_score  = 1

    v_ratios = []
    for idx, label, conf in results:
        if label == "dark spot":
            c = final_cleaned[idx - 1]
            mask = np.zeros_like(v, dtype=np.uint8)
            cv2.drawContours(mask, [c], -1, 255, -1)
            lesion_v = v[mask == 255]
            lesion_median = np.median(lesion_v)
            ratio = lesion_median / (healthy_skin_V + 1e-5)
            v_ratios.append((c, ratio))

    ratios_only = [r for _, r in v_ratios]
    bin_edges = np.histogram_bin_edges(ratios_only, bins=5)
    colored_output = img_bgr.copy()
    weighted_sum = 0
    for c, ratio in v_ratios:
        bin_index = np.digitize(ratio, bin_edges, right=True) - 1
        bin_index = max(0, min(bin_index, 4))
        color = [(0, 0, 255), (128, 0, 128), (255, 0, 0), (0, 255, 0), (0, 0, 0)][bin_index]
        cv2.drawContours(colored_output, [c], -1, color, 1)
        weighted_sum += (1 / ratio) * cv2.contourArea(c)

    severity_score = weighted_sum / total_area
    darkspot_score_final = round(linear_interpolate_severity(severity_score), 2)
    return darkspot_score_final, acne_score


######################################OILINESS#########################################

import cv2
import numpy as np
from sklearn.cluster import KMeans
from scipy.stats import gaussian_kde


def get_kde_thresh(data, high=True):
    data = data.flatten()
    if len(data) == 0:
        return 128
    if np.std(data) < 1e-3 or len(np.unique(data)) < 10:
        return int(np.percentile(data, 90 if high else 10))
    try:
        kde = gaussian_kde(data)
        xs = np.linspace(np.min(data), np.max(data), 1000)
        density = kde(xs)
        peak_idx = np.argmax(density)
        if high:
            for i in range(peak_idx, len(xs)):
                if density[i] < density[peak_idx] * 0.5:
                    return int(xs[i])
            return int(xs[-1])
        else:
            for i in range(peak_idx, 0, -1):
                if density[i] < density[peak_idx] * 0.5:
                    return int(xs[i])
            return int(xs[0])
    except np.linalg.LinAlgError:
        return int(np.percentile(data, 90 if high else 10))

def subsample(data, max_samples=2000):
    if len(data) > max_samples:
        idx = np.random.choice(len(data), size=max_samples, replace=False)
        return data[idx]
    return data

@timer
def compute_oiliness_score(img_rgb):
    # --- Create mask to exclude purple padding ---
    # --- Purple Mask ---
    img_np = np.array(img_rgb)

    lower_purple = np.array([120, 0, 120])
    upper_purple = np.array([160, 50, 160])
    purple_mask = cv2.inRange(img_np, lower_purple, upper_purple)
    valid_mask = (purple_mask == 0)

    # --- HSV Channels -------------------------------------------------------
    img_hsv = cv2.cvtColor(img_np, cv2.COLOR_RGB2HSV)
    v = img_hsv[:, :, 2]
    s = img_hsv[:, :, 1]

    v_valid = subsample(v[valid_mask])
    s_valid = subsample(s[valid_mask])

    v_base = get_kde_thresh(v_valid, high=True)
    s_base = get_kde_thresh(s_valid, high=False)
    v_thresh = int(v_base * 0.93125)
    s_thresh = int(s_base * 1.05)

    v_mask = ((v >= v_thresh) & valid_mask).astype(np.uint8)
    s_mask = ((s <= s_thresh) & valid_mask).astype(np.uint8)
    oil_mask = cv2.bitwise_and(v_mask, s_mask) * 255

    # --- Bright Mask via RELAXED RGB Sum ------------------------------------
    rgb_sum = img_np.sum(axis=2)
    bright_base = np.percentile(rgb_sum[valid_mask], 95)
    bright_thresh = bright_base * 0.925
    bright_mask = ((rgb_sum >= bright_thresh) & valid_mask).astype(np.uint8) * 255

    # --- Overlays -----------------------------------------------------------
    overlay_oil = img_np.copy()
    overlay_oil[(oil_mask == 255) & valid_mask] = [255, 255, 0]
    blended_oil = cv2.addWeighted(img_np, 0.7, overlay_oil, 0.3, 0)

    overlay_bright = img_np.copy()
    overlay_bright[(bright_mask == 255) & valid_mask] = [0, 255, 0]
    blended_bright = cv2.addWeighted(img_np, 0.7, overlay_bright, 0.3, 0)

    combined = img_np.copy()
    combined[(bright_mask == 255) & valid_mask] = [0, 255, 0]
    combined[(oil_mask == 255) & valid_mask] = [255, 255, 0]
    blended_combined = cv2.addWeighted(img_np, 0.6, combined, 0.4, 0)

    # --- Score Calculation --------------------------------------------------
    intersection_mask = ((oil_mask == 255) & (bright_mask == 255) & valid_mask)
    union_mask = (((oil_mask == 255) | (bright_mask == 255)) & valid_mask)

    intersection_pixels = np.sum(intersection_mask)
    union_pixels = np.sum(union_mask)
    total_valid_pixels = np.sum(valid_mask)

    overlap_ratio = intersection_pixels / total_valid_pixels if total_valid_pixels > 0 else 0
    jaccard_ratio = intersection_pixels / union_pixels if union_pixels > 0 else 0

    bright_pixels = np.sum(bright_mask == 255)
    bright_coverage_ratio = bright_pixels / total_valid_pixels if total_valid_pixels > 0 else 0

    # --- Quality of match (same as before) ----------------------------------
    if bright_coverage_ratio >= 0.7:
        quality = overlap_ratio
    else:
        quality = (overlap_ratio ** 0.75) * (jaccard_ratio ** 0.5)

    # --- NEW: resolution‑aware dampening ------------------------------------
    coverage   = total_valid_pixels / valid_mask.size     # skin to image ratio (0–1)
    spread     = coverage ** 0.5                          # √coverage
    N0         = 20_000                                   # pixels for 63% confidence
    confidence = 1 - np.exp(- total_valid_pixels / N0)    # 0–1 confidence term

    final_score = quality * spread * confidence
    # -----------------------------------------------------------------------

    # --- Linear Interpolation to 0–10 scale --------------------------------
    score_breakpoints = [0.0, 0.04, 0.06, 0.08, 0.10, 0.12, 0.15, 0.18, 0.21, 0.27, 0.3]
    score_values      = [1.0,  2.0,  3.0,  4.0,  5.0,  6.0,  7.0,  8.0,  9.0,  9.5, 10.0]
    score_out_of_10 = float(np.interp(final_score, score_breakpoints, score_values))
    score_out_of_10 = round(score_out_of_10, 2)

    return score_out_of_10,blended_oil


###############################WRINKLES#########################################

def compute_vesselness(gray_img, sigmas=[5]):
    norm_img = gray_img.astype(np.float32) / 255.0
    vessel = frangi(norm_img, sigmas=sigmas, black_ridges=True)
    vessel_norm = ((vessel - vessel.min()) / (np.ptp(vessel) + 1e-9))
    return vessel_norm

def wrinkle_mask_overlay(rgb_image, color=(255, 0, 0), sigmas=[5]):
    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
    vessel_norm = compute_vesselness(gray, sigmas=sigmas)

    vessel_binary = (vessel_norm > 0.2).astype(np.uint8)
    skel = skeletonize(vessel_binary).astype(np.uint8) * 255
    skeleton_final = skeletonize(skel > 0).astype(np.uint8)

    # Filter out very short lines
    labeled = measure.label(skeleton_final, connectivity=2)
    props = measure.regionprops(labeled)
    clean_mask = np.zeros_like(skeleton_final, dtype=np.uint8)
    for prop in props:
        if prop.area >= 3:
            clean_mask[labeled == prop.label] = 1

    overlay = rgb_image.copy()
    overlay[clean_mask > 0] = color
    return overlay, clean_mask

def compute_wrinkle_score(wrinkle_mask, mask=None):
    if mask is None:
        mask = np.ones_like(wrinkle_mask, dtype=np.uint8) * 255

    valid_region = (mask == 255)
    if np.count_nonzero(valid_region) == 0:
        return 0

    raw_score = np.sum((wrinkle_mask > 0) & valid_region) / np.count_nonzero(valid_region)

    # Clamp input to [1, 2.5]
    raw_score = max(1.0, min(raw_score, 2.5))

    # Linear mapping from [1, 2.5] → [1, 9]
    mapped_score = 1 + (raw_score - 1) * ((9 - 1) / (2.5 - 0.9))

    # Cap at 9.5
    return round(min(mapped_score, 9.5), 2)
# # Run wrinkle overlay
# selected_regions = [ 'forehead','left_side_eye', 'right_side_eye']
# wrinkle_scores = {}
# wrinkle_overlays = {}
# for region in selected_regions:
#     if region in patches:
#         overlay_img, wrinkle_mask = wrinkle_overlay_single(patches[region])
#         raw_score = np.sum(wrinkle_mask > 0) / wrinkle_mask.size
#         score = round(min(raw_score / 0.02, 1.0) * 10)
#         wrinkle_scores[region] = score
#         wrinkle_overlays[region] = overlay_img
#     else:
#         print(f"Warning: {region} patch not found in patches dictionary.")



#######################GLOW INDEX##################################

@timer
def compute_glowindex_score(img_rgb):
    def compute_evenness_map(image, cluster_size=20):
        h, w = image.shape[:2]
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        scores = np.zeros((h // cluster_size, w // cluster_size), dtype=np.float32)
        margin = 3 * cluster_size

        for i in range(0, h - cluster_size, cluster_size):
            for j in range(0, w - cluster_size, cluster_size):
                if i < margin or j < margin or i > h - margin - cluster_size or j > w - margin - cluster_size:
                    continue
                patch = image_rgb[i:i+cluster_size, j:j+cluster_size]
                r0, g0, b0 = [np.mean(patch[:, :, k]) for k in range(3)]
                total_diff, count = 0, 0
                for dx, dy in [(0, cluster_size), (cluster_size, 0), (cluster_size, cluster_size), (cluster_size, -cluster_size)]:
                    ni, nj = i + dx, j + dy
                    if 0 <= ni < h - cluster_size and 0 <= nj < w - cluster_size:
                        neighbor = image_rgb[ni:ni+cluster_size, nj:nj+cluster_size]
                        r1, g1, b1 = [np.mean(neighbor[:, :, k]) for k in range(3)]
                        diff = (abs(r0 - r1) + abs(g0 - g1) + abs(b0 - b1)) / 3
                        total_diff += diff
                        count += 1
                if count > 0:
                    scores[i // cluster_size, j // cluster_size] = total_diff / count
        return scores

    def highlight_top_evenness_clusters(image, scores, cluster_size=20, high_pct=90, mid_pct=80):
        # high_thresh = np.percentile(scores[scores > 0], high_pct)
        # mid_thresh = np.percentile(scores[scores > 0], mid_pct)
        valid_scores = scores[scores > 0]
        if len(valid_scores) == 0:
         return image.copy(), 0, 0  # return default if no data

        high_thresh = np.percentile(valid_scores, high_pct)
        mid_thresh = np.percentile(valid_scores, mid_pct)

        h, w = image.shape[:2]
        overlay = image.copy()
        high_scores, mid_scores = [], []

        for i in range(scores.shape[0]):
            for j in range(scores.shape[1]):
                score = scores[i, j]
                if score >= high_thresh:
                    color = (0, 0, 255)
                    high_scores.append(score)
                elif score >= mid_thresh:
                    color = (255, 0, 0)
                    mid_scores.append(score)
                else:
                    continue
                top_left = (j * cluster_size, i * cluster_size)
                bottom_right = (top_left[0] + cluster_size, top_left[1] + cluster_size)
                cv2.rectangle(overlay, top_left, bottom_right, color, 1)

        avg_high = np.mean(high_scores) if high_scores else 0
        avg_mid = np.mean(mid_scores) if mid_scores else 0
        return overlay, avg_high, avg_mid

    def compute_glcm_smoothness(image):
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        denoised = median(gray, disk(1))
        resized = cv2.resize(denoised, (64, 64))
        glcm = graycomatrix(resized, distances=[1, 2],
                            angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                            symmetric=True, normed=True)
        contrast = graycoprops(glcm, 'contrast').mean()

        if contrast <= 7.5:
            score = 10
        elif contrast <= 15:
            score = 9
        elif contrast <= 30:
            score = 8
        elif contrast <= 40:
            score = 7
        elif contrast <= 50:
            score = 6
        elif contrast <= 60:
            score = 5
        elif contrast <= 70:
            score = 4
        elif contrast <= 85:
            score = 3
        elif contrast <= 100:
            score = 2
        else:
            score = 1

        return contrast, score, glcm[:, :, 0, 0]

    # --- Actual Execution ---
    img_bgr=cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    h, w = img_bgr.shape[:2]
    # cluster = int(min(h, w) / 40)
    cluster = max(5, int(min(h, w) / 40))  # Ensure cluster_size is at least 5
    scores = compute_evenness_map(img_bgr, cluster)
    overlay, avg_hi, avg_mid = highlight_top_evenness_clusters(img_bgr, scores, cluster)

    combined = (20 - avg_hi) * 0.3 + 0.7 * (10 - avg_mid)
    evenness_score = max(1, min(10, int(round(10 if combined >= 10 else combined))))  # clamp to [1, 10]

    contrast, smoothness_score, glcm_matrix = compute_glcm_smoothness(img_bgr)

    final_score = round((evenness_score + smoothness_score) / 2, 2)

    return final_score

# glowindex_scores = {}

# for name, img_rgb in patches.items():
#     even, smooth, final = compute_evenness_smoothness_score(img_rgb)
#     glowindex_scores[name] = {
#         'glow_index_score': final
#     }



###################################DRYNESS#########################################

# --- Texture score ---
def texture(image_bgr):
    lab = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2LAB)
    l_channel = lab[:, :, 0]
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(l_channel)
    blur1 = cv2.GaussianBlur(enhanced, (5, 5), 0)
    blur2 = cv2.GaussianBlur(enhanced, (15, 15), 0)
    dog = cv2.subtract(blur1, blur2)
    adaptive_thresh = cv2.adaptiveThreshold(
        dog, 255,
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        blockSize=11,
        C=4
    )
    adaptive_thresh_inv = cv2.bitwise_not(adaptive_thresh)
    contours, _ = cv2.findContours(adaptive_thresh_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    # Compute total area covered by contours
    total_contour_area = sum(cv2.contourArea(cnt) for cnt in contours)
    patch_area = image_bgr.shape[0] * image_bgr.shape[1]

    # Final score
    contour_score = total_contour_area / patch_area

    if contour_score <= 1:
        score = 1
    elif contour_score <= 2:
        score = 2
    elif contour_score <= 3:
        score = 3
    elif contour_score <= 4:
        score = 4
    elif contour_score <= 5:
        score = 5
    elif contour_score <= 6:
        score = 6
    elif contour_score <= 7:
        score = 7
    elif contour_score <= 8:
        score = 8
    elif contour_score <= 9:
        score = 9
    else:
        score = 10

    return score, contour_score

# --- Roughness score ---
def compute_glcm_roughness(image_bgr):
    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)
    denoised = median(gray, disk(1))
    resized = cv2.resize(denoised, (64, 64))
    glcm = graycomatrix(resized, distances=[1, 2],
                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],
                        symmetric=True, normed=True)
    contrast = graycoprops(glcm, 'contrast').mean()

    if contrast <= 7.5:
        score = 1
    elif contrast <= 15:
        score = 2
    elif contrast <= 30:
        score = 3
    elif contrast <= 40:
        score = 4
    elif contrast <= 50:
        score = 5
    elif contrast <= 60:
        score = 6
    elif contrast <= 70:
        score = 7
    elif contrast <= 85:
        score = 8
    elif contrast <= 100:
        score = 9
    else:
        score = 10

    return score

# --- Wrapper Function ---
@timer
def compute_dryness_score(image_rgb):
    image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)
    texture_score, contour_score = texture(image_bgr)
    roughness_score = compute_glcm_roughness(image_bgr)
    final_score = round((texture_score + roughness_score) / 2)

    return final_score

# dryness_scores = {}

# for name, img_rgb in patches.items():
#     final = compute_flake_texture_roughness_score(img_rgb)
#     dryness_scores[name] = {
#         'dryness_score': final
#     }
# NOTE: Due to message size limitations, the full code is too long for a single snippet.
# We'll break it down in the following steps and update this module section by section.

# === Master Entry Function ===
# def analyze_image_all_regions(image_np):
#     image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
#     patches = process_image(image_bgr)
#     results = {}

#     dc_scores = {}
#     for region in ['left_below_eye', 'right_below_eye']:
#         if region in patches:
#             dc_scores[region] = compute_darkcircle_score(patches[region])
#     results['dark_circles'] = dc_scores

#     ds_scores = {}
#     for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
#         if region in patches:
#             score, _ = compute_darkspot_score(patches[region])
#             ds_scores[region] = score
#     results['dark_spots'] = ds_scores

#     oil_scores = {}
#     for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
#         if region in patches:
#             score, _ = compute_oiliness_score(patches[region])
#             oil_scores[region] = score
#     results['oiliness'] = oil_scores

#     wrinkle_scores = {}
#     for region in ['forehead', 'left_side_eye', 'right_side_eye']:
#         if region in patches:
#             _, mask = wrinkle_overlay_single(patches[region])
#             raw_score = np.sum(mask > 0) / mask.size
#             wrinkle_scores[region] = round(min(raw_score / 0.02, 1.0) * 10)
#     results['wrinkles'] = wrinkle_scores

#     glow_scores = {}
#     for name, img in patches.items():
#         even, smooth, final = compute_evenness_smoothness_score(img)
#         glow_scores[name] = final
#     results['glow_index'] = glow_scores

#     dryness_scores = {}
#     for name, img in patches.items():
#         dryness_scores[name] = compute_flake_texture_roughness_score(img)
#     results['dryness'] = dryness_scores

    
#     # return results
#         # Print all results clearly
#     print("\n--- Final Region-wise Scores ---", flush=True)
#     for category, region_scores in results.items():
#         print(f"\n{category.upper()}:", flush=True)
#     for region, score in region_scores.items():
#         print(f"  {region}: {score}", flush=True)


from collections import defaultdict
import numpy as np
import cv2
import time


from collections import defaultdict
import cv2
import numpy as np

def analyze_image_all_regions(image_np):
    results = {}
    all_condition_scores = defaultdict(dict)

    try:
        print("🔄 [1] Converting to BGR and extracting patches")
        image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)
        patches = process_image(image_bgr)
        print(f"    ✅ Patches keys: {list(patches.keys())}")

        print("🟤 [2] Computing dark circle scores")
        for region in ['left_below_eye', 'right_below_eye']:
            score = compute_darkcircle_score(patches[region])
            all_condition_scores['dark_circle_score'][region] = score

        print("⚫ [3] Computing dark spot scores")
        for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
            raw = compute_darkspot_score(patches[region])
            score = raw[0] if isinstance(raw, (tuple, list)) else raw
            all_condition_scores['darkspot_score'][region] = score

        print("💧 [4] Computing oiliness scores")
        for region in ['left_cheek', 'right_cheek', 'forehead', 'nose', 'chin']:
            score, _ = compute_oiliness_score(patches[region])
            all_condition_scores['oiliness_score'][region] = score
        l = all_condition_scores['oiliness_score'].get('left_cheek', 0)
        r = all_condition_scores['oiliness_score'].get('right_cheek', 0)
        avg = round((l + r) / 2, 2)
        all_condition_scores['oiliness_score']['left_cheek'] = avg
        all_condition_scores['oiliness_score']['right_cheek'] = avg

        print("🧓 [5] Computing wrinkle scores")
        for region in ['forehead', 'left_eye', 'right_eye']:
            patch = patches[region]
            if region in ['left_eye', 'right_eye']:
                img, mask = patch
                _, wrinkle_mask = wrinkle_mask_overlay(img)
                score = compute_wrinkle_score(wrinkle_mask, mask)
            else:
                _, wrinkle_mask = wrinkle_mask_overlay(patch)
                raw_ratio = np.sum(wrinkle_mask > 0) / wrinkle_mask.size
                score = round(min(raw_ratio / 0.02, 1.0) * 10)
            all_condition_scores['wrinkle_score'][region] = score

        print("💦 [6] Computing dryness scores")
        for region in ['left_cheek','right_cheek','nose','chin','forehead','left_below_eye','right_below_eye']:
            if region in patches:
                score = compute_dryness_score(patches[region])
                all_condition_scores['dryness_score'][region] = int(score)

        print("✨ [7] Computing glow index scores")
        for region in ['left_cheek','right_cheek','nose','chin','forehead','left_below_eye','right_below_eye']:
            if region in patches:
                score = compute_glowindex_score(patches[region])
                all_condition_scores['glow_index_score'][region] = int(score)

        print("🔧 [8] Adjusting glow index with penalties")
        region_to_conditions = defaultdict(set)
        mapping = {
            "oiliness_score": ['left_cheek','right_cheek','forehead','nose','chin'],
            "wrinkle_score": ['forehead','left_eye','right_eye'],
            "dark_circle_score": ['left_below_eye','right_below_eye'],
            "darkspot_score": ['left_cheek','right_cheek','nose','chin'],
            "dryness_score": ['left_cheek','right_cheek','nose','chin','forehead','left_below_eye','right_below_eye'],
            "glow_index_score": ['left_cheek','right_cheek','nose','chin','forehead','left_below_eye','right_below_eye'],
        }
        for cond, regs in mapping.items():
            for region in regs:
                region_to_conditions[region].add(cond)

        adjusted = {}
        for region, glow in all_condition_scores['glow_index_score'].items():
            relevant = region_to_conditions[region] - {'glow_index_score'}
            penalty = total_wt = 0
            for cond in relevant:
                val = all_condition_scores[cond].get(region)
                if val is None: continue
                wt = 0.1
                penalty += wt * (val / 10)
                total_wt += wt
            final_penalty = penalty / total_wt if total_wt else 0
            adjusted[region] = round(glow * (1-final_penalty), 2)
        all_condition_scores['glow_index_score'] = adjusted

        print("🏁 [9] Preparing final results")
        results['dark_circles'] = all_condition_scores['dark_circle_score']
        results['dark_spots']   = all_condition_scores['darkspot_score']
        results['oiliness']     = all_condition_scores['oiliness_score']
        results['wrinkles']     = all_condition_scores['wrinkle_score']
        results['dryness']      = all_condition_scores['dryness_score']
        results['glow_index']   = all_condition_scores['glow_index_score']

        print("\n--- Final Region-wise Scores ---")
        for cat, scores in results.items():
            print(f"{cat.upper()}: {scores}")

    except Exception as e:
        print("❌ Analysis error:", e)

    return results
